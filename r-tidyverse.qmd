---
title: Introduction to R and the Tidyverse
author: Clemens Schmid
format:
  html:
    link-external-icon: true
    link-external-newwindow: true
editor_options: 
  chunk_output_type: console
---

::: callout-note
This session is typically ran held in parallel to the Introduction to Python and Pandas. Participants of the summer schools chose which to attend based on their prior experience. We recommend this session if you have no experience with neither R nor Python.
:::

::: callout-tip
For this chapter's exercises, if not already performed, you will need to create the [conda environment](before-you-start.qmd#creating-a-conda-environment) from the `yml` file in the following [link](https://github.com/SPAAM-community/intro-to-ancient-metagenomics-book/raw/main/assets/envs/r-tidyverse.yml) (right click and save as to download), and once created, activate the environment with:

``` bash
conda activate r-tidyverse
```
:::

## Lecture

Lecture slides and video from the [2022 edition of the summer school](https://www.spaam-community.org/wss-summer-school/#/2022/README).

<iframe src="https://docs.google.com/viewer?url=https://raw.githubusercontent.com/nevrome/spaam_r_tidyverse_intro_2h/main/presentation.pdf&amp;embedded=true" width="100%" height="400px">

</iframe>

PDF version of these slides can be downloaded from [here](https://github.com/nevrome/spaam_r_tidyverse_intro_2h/raw/main/presentation.pdf).

<iframe width="100%" height="400px" src="https://www.youtube.com/embed/b32FRYWwSrg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>

</iframe>

***

```{r, echo=FALSE}
# Set global options
knitr::opts_chunk$set(attr.output = "style='border: 1px; border-style: solid; margin-left: 10px; margin-right: 10px;'")
```

## The working environment

### R, RStudio and the tidyverse

- R is a fully featured programming language, but it excels as an environment for (statistical) data analysis (<https://www.r-project.org>)

- RStudio is an integrated development environment (IDE) for R (and other languages): (<https://www.rstudio.com/products/rstudio>)

- The tidyverse is a collection of R packages with well-designed and consistent interfaces for the main steps of data analysis: loading, transforming and plotting data (<https://www.tidyverse.org>)
  - This introduction works with tidyverse ~v1.3.0
  - We will learn about `readr`, `tibble`, `ggplot2`, `dplyr`, `magrittr` and `tidyr`
  - `forcats` will be briefly mentioned
  - `purrr` and `stringr` are left out

## Loading data into tibbles

### Reading data with readr

- With R we usually operate on data in our computer's memory
- The tidyverse provides the package `readr` to read data from text files into the memory
- `readr` can read from our file system or the internet
- It provides functions to read data in almost any (text) format:

```{r eval=FALSE}
readr::read_csv()   # .csv files -> see data/penguins.csv
readr::read_tsv()   # .tsv files
readr::read_delim() # tabular files with an arbitrary separator
readr::read_fwf()   # fixed width files
readr::read_lines() # read linewise to parse yourself 
```

### How does the interface of `read_csv` work?

- We can learn more about a function with the `?` operator
- To open a help file for a specific function run `?<function_name>` (e.g. `?readr::read_csv`) in the R console
- `readr::read_csv` has many options to specify how to read a text file

```{r eval=FALSE}
read_csv(
  file,                      # The path to the file we want to read
  col_names = TRUE,          # Are there column names?
  col_types = NULL,          # Which types do the columns have? NULL -> auto
  locale = default_locale(), # How is information encoded in this file?
  na = c("", "NA"),          # Which values mean "no data"
  trim_ws = TRUE,            # Should superfluous white-spaces be removed?
  skip = 0,                  # Skip X lines at the beginning of the file
  n_max = Inf,               # Only read X lines
  skip_empty_rows = TRUE,    # Should empty lines be ignored? 
  comment = "",              # Should comment lines be ignored?
  name_repair = "unique",    # How should "broken" column names be fixed
  ...
)
```

### What does `readr` produce? The `tibble`!

- To read a .csv file (here `"assets/data/r-tidyverse/penguins.csv"`) into a variable (here `peng_auto`) run

```{r}
peng_auto <- readr::read_csv("assets/data/r-tidyverse/penguins.csv")
```

- `readr` first prints some information on the number and type of rows and columns it discovered in the file
- It automatically detects column types -- but you can also define them manually

```{r}
peng <- readr::read_csv(
  "assets/data/r-tidyverse/penguins.csv",
  col_types = "iccddcc" # this string encodes the desired types for each column
)
```

- It then returns an in-memory representation of this data, a `tibble`
- A `tibble` is a "data frame", a tabular data structure with rows and columns
- Unlike a simple array, each column can have another data type

### How to look at a `tibble`?

- Typing the name of any object into the R console will print an overview to the console

```{r}
peng
```

- But there are various other ways to inspect the content of a `tibble` 

```{r, eval=FALSE}
str(peng)     # A structural overview of an object
summary(peng) # A human-readable summary of an object
View(peng)    # RStudio's interactive data browser
```

## Plotting data in `tibble`s

### `ggplot2` and the "grammar of graphics"

- To understand and present data, we usually have to visualize it
- `ggplot2` is an R package that offers an unusual, but powerful and logical interface for this task
- The following example describes a stacked bar chart

```{r}
library(ggplot2) # Loading a library to use its functions without ::
```

```{r}
ggplot(          # Every plot starts with a call to the ggplot() function
  data = peng    # This function can also take the input tibble
) +              # The plot consists of individual functions linked with "+"
  geom_bar(        # "geoms" define the plot layers we want to draw
    mapping = aes(   # The aes() function maps variables to visual properties
      x = island,      # publication_year -> x-axis
      fill = species   # community_type -> fill color
    )
  )
```

- A `geom_*` combines data (here `peng`), a geometry (here vertical, stacked bars) and a statistical transformation (here counting the number of penguins per island and species)
- `ggplot2` features many such geoms: A good overview is provided by this cheatsheet: <https://rstudio.github.io/cheatsheets/html/data-visualization.html>
- Beyond `geom`s, a ggplot can be further specified with (among others) `scale`s, `facet`s and `theme`s

### `scale`s control the behaviour of visual elements

- Here is another plot to demonstrate this: Boxplots of penguin weight per species

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g))
```

- Let's assume we had some extreme outliers in this dataset
- To simulate this, we replace some random weights with extreme values

```{r}
set.seed(1234) # We set a seed for reproducible randomness
peng_out <- peng
peng_out$body_mass_g[sample(1:nrow(peng_out), 10)] <- 100000 + 100000 * runif(10)
```

- Now we plot the dataset with these "outliers"

```{r}
ggplot(peng_out) +
  geom_boxplot(aes(x = species, y = body_mass_g))
```

- This is not well readable, because the extreme outliers dictate the scale of the y-axis
- A 100kg penguin is a scary thought and we would probably remove these outliers, but let's assume they are valid observation we want to include in the plot
- To mitigate this issue we can change the **scale** of different visual elements - e.g. the y-axis

```{r}
ggplot(peng_out) +
  geom_boxplot(aes(x = species, y = body_mass_g)) +
  scale_y_log10() # adding the log-scale improves readability
```

- We will now go back to the normal dataset without the artificial outliers

### Colour `scale`s

- (Fill) colour is a visual element of a plot and its scaling can be adjusted as well

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g, fill = species)) +
  scale_fill_viridis_d(option = "C")
```

- We use the `scale_*` function to select the visually appealing (and robust to colourblindness) viridis colour palettes (<https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html>)

### More variables! Defining plot matrices via `facet`s

- In the previous this example we didn't add additional information with the fill colour, as the plot already distinguished by species on the x-axis
- We can instead use this to encode more information, for example by mapping sex to the fill colour

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g, fill = sex))
```

- Another way to visualize more variables at once is to split the plot by categories into **facets**, so sub-plots per category
- Here we split by sex, which is already mapped to the fill colour

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g, fill = sex)) +
  facet_wrap(~sex)
```

- The fill colour is therefore free again to show yet another variable, for example the year a given penguin was examined

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g, fill = year)) +
  facet_wrap(~sex)
```

### Setting purely aesthetic settings with `theme`

- Aesthetic changes can be applied as part of the `theme`, which allows for very detailed configuration (see `?theme`)
- Here we rotate the x-axis labels by 45Â°

```{r}
ggplot(peng) +
  geom_boxplot(aes(x = species, y = body_mass_g, fill = year)) +
  facet_wrap(~sex) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

### Ordering elements in a plot with `factors`

- R supports defining ordinal data with `factor`s
- This can be used to set the order of elements in a plot, e.g. the order of bars in a bar chart
- We do not cover `factor`s beyond the following example here, although the tidyverse includes a package (`forcats`) specifically for that purpose

***

- Elements based on `character` columns are generally ordered alphabetically

```{r}
ggplot(peng) + geom_bar(aes(x = species)) # bars are alphabetically ordered
```

- With `forcats::fct_reorder` we can transform an input vector to a `factor`, ordered by a summary statistic (even based on another vector)

```{r}
peng2 <- peng
peng2$species_ordered <- forcats::fct_reorder(
  peng2$species,
  peng2$species, length
)
```

- With this change, the plot is ordered according to the intrinsic order defined for `species_ordered`

```{r}
ggplot(peng2) + geom_bar(aes(x = species_ordered)) # bars are ordered by size
```

### Exercise

1. Look at the `mtcars` dataset and read up on the meaning of its variables with the help operator `?`. `mtcars` is a test dataset integrated in R and can be accessed by typing `mtcars` in the console.

2. Visualize the relationship between *Gross horsepower* and *1/4 mile time*

```{r}

```

3. Integrate the *Number of cylinders* into your plot as an additional variable

```{r}

```

<details>
<summary>Possible solutions</summary>

```{r}
?mtcars
```

```{r}
ggplot(mtcars) +
  geom_point(aes(x = hp, y = qsec))
```

```{r}
ggplot(mtcars) +
  geom_point(aes(x = hp, y = qsec, color = as.factor(cyl)))
```

</details>

## Conditional queries on tibbles

### Selecting columns and filtering rows with `select` and `filter`

```{r, echo=FALSE}
# technical adjustments for rendering
old_options <- options(
  pillar.print_max = 5,
  pillar.print_min = 5,
  pillar.advice = FALSE
)
```

- The `dplyr` package includes powerful functions to subset data in tibbles based on conditions.
- `dplyr::select` allows to select columns

```{r}
dplyr::select(peng, id, flipper_length_mm) # reduce tibble to two columns
dplyr::select(peng, -island, -flipper_length_mm) # remove two columns 
```

- `dplyr::filter` allows for conditional filtering of rows

```{r}
dplyr::filter(peng, year == 2007) # penguins examined in 2007
dplyr::filter(peng, year == 2007 |
                    year == 2009) # penguins examined in 2007 OR 2009
dplyr::filter(peng,                    # an alternative way to express
              year %in% c(2007, 2009)) # OR with the match operator "%in%"
dplyr::filter(peng, species == "Adelie" & 
                    body_mass_g >= 4000) # Adelie penguins heavier than 4kg
```

### Chaining functions together with the pipe `%>%`

- A core feature of the tidyverse is the pipe `%>%` in the `magrittr` package
- This infix operator allows to chain data and operations for concise and clear data analysis syntax

```{r}
library(magrittr)
peng %>% dplyr::filter(year == 2007)
```

- It forwards the LHS (left-hand side) as the first argument of the function appearing on the RHS (right-hand side), which enables sequences of functions ("tidyverse style")

```{r}
peng %>%
  dplyr::select(id, species, body_mass_g) %>%
  dplyr::filter(species == "Adelie" & body_mass_g >= 4000) %>%
  nrow() # count the resulting rows
```

- `magrittr` also offers some more operators, among which the extraction `%$%` is particularly useful to easily extract individual variables

```{r}
peng %>%
  dplyr::filter(island == "Biscoe") %$%
  species %>% # extract the species column as a vector
  unique()    # get the unique elements of said vector
```

- Here we already use the base R summary function `unique`

### Summary statistics in `base` R

- Summarising and counting data is indispensable and R offers all basic operations you would expect in its `base` package

```{r}
chinstraps_weights <- peng %>% dplyr::filter(species == "Chinstrap") %$% body_mass_g

length(chinstraps_weights) # length/size of a vector
unique(chinstraps_weights) # unique elements of a vector

min(chinstraps_weights) # minimum
max(chinstraps_weights) # maximum

mean(chinstraps_weights) # mean
median(chinstraps_weights) # median

var(chinstraps_weights) # variance
sd(chinstraps_weights) # standard deviation
quantile(chinstraps_weights, probs = 0.75) # quantiles for the given probabilities
```

- Many of these functions can ignore missing values with an option `na.rm = TRUE`

### Group-wise summaries with `group_by` and `summarise`

- These summary statistics are particular useful when applied to conditional subsets of a dataset
- `dplyr` allows such summary operations with a combination of the functions `group_by` and `summarise`, where the former tags a `tibble` with categories based on its variables and the latter reduces it to these groups while simultanously creating new columns

```{r}
peng %>%
  dplyr::group_by(species) %>% # group the tibble by the material column
  dplyr::summarise(
    min_weight = min(body_mass_g),       # new col: min weight for each group
    median_weight = median(body_mass_g), # new col: median weight for each group
    max_weight = max(body_mass_g)        # new col: max weight for each group
  )
```

- Grouping can also be applied across multiple columns at once

```{r}
peng %>%
  dplyr::group_by(species, year) %>% # group by species and year
  dplyr::summarise(
    n = dplyr::n(),  # a new column: number of penguins for each group
    .groups = "drop" # drop the grouping after this summary operation
  )
```

- If we group by more than one variable, then `summarise` will not entirely remove the group tagging when generating the result dataset. We can force this with `.groups = "drop"` to avoid undesired behaviour with this dataset later on

### Sorting and slicing tibbles with `arrange` and `slice`

- `dplyr` allows to `arrange` tibbles by one or multiple columns

```{r}
peng %>% dplyr::arrange(sex) # sort by sex
peng %>% dplyr::arrange(sex, body_mass_g) # sort by sex and weight
peng %>% dplyr::arrange(dplyr::desc(body_mass_g)) # sort descending
```

- Sorting also works within groups and can be paired with `slice` to extract extreme values per group
- Here we extract the heaviest individuals per species

```{r}
peng %>%
  dplyr::group_by(species) %>% # group by species
  dplyr::arrange(dplyr::desc(body_mass_g)) %>% # sort by weight within (!) groups
  dplyr::slice_head(n = 3) %>% # keep the first three penguins per group
  dplyr::ungroup()             # remove the still lingering grouping
```

- Slicing is also the relevant operation to take random samples from the observations in a `tibble`

```{r}
peng %>% dplyr::slice_sample(n = 10)
```

### Exercise

For this exercise we once more go back to the `mtcars` dataset. See `?mtcars` for more details.

1. Determine the number of cars with four *forward gears* (`gear`) in the `mtcars` dataset

```{r}

```

2. Determine the mean *1/4 mile time* (`qsec`) per *Number of cylinders* (`cyl`) group

```{r}

```

3. Identify the least efficient cars for both *transmission types* (`am`)

```{r}

```

<details>
<summary>Possible solutions</summary>

```{r}
mtcars %>%
  dplyr::filter(gear == 4) %>%
  nrow()
```

```{r}
mtcars %>% dplyr::group_by(cyl) %>%
  dplyr::summarise(
    qsec_mean = mean(qsec)
  )
```

```{r}
mtcars2 <- tibble::rownames_to_column(mtcars, var = "car")
mtcars2 %>%
  dplyr::group_by(am) %>%
  dplyr::arrange(mpg) %>%
  dplyr::slice_head() %$%
  car
```

</details>

## Transforming and manipulating tibbles

### Renaming and reordering columns with `rename` and `relocate`

- Columns in tibbles can be renamed with `dplyr::rename`

```{r}
peng %>% dplyr::rename(penguin_name = id) # rename a column
```

- And with `dplyr::relocate` they can be reordered

```{r}
peng %>% dplyr::relocate(year, .before = species) # reorder columns
```

### Adding columns to tibbles with `mutate` and `transmute`

- A common application of data manipulation is adding new, derived columns, that combine or modify the information in the already available columns. `dplyr` offers this core feature with `mutate`

```{r}
peng %>%
  dplyr::mutate(          # add a column that
    kg = body_mass_g/1000 # manipulates an existing column
  )
```

- `dplyr::transmute` has the same interface as `dplyr::mutate`, but it removes all columns except for the newly created ones

```{r}
peng %>%
  dplyr::transmute(
    id = paste("Penguin Nr.", id), # overwrite this column
    flipper_length_mm               # select this column
)
```

- `tibble::add_column` behaves as `dplyr::mutate`, but gives more control over column position

```{r}
peng %>% tibble::add_column(
  flipper_length_cm = .$flipper_length_mm/10, # not the . representing the LHS of the pipe
  .after = "flipper_length_mm"
)
```

- `dplyr::mutate` can also be combined with `dplyr::group_by` (instead of `dplyr::summarise`) to add information on a group level. This is relevant, when a value for an individual entity should be put into context of a group-wise summary statistic

```{r}
peng %>%
  dplyr::group_by(species, sex, year) %>%
  dplyr::mutate(
    mean_weight = mean(body_mass_g, na.rm = T),
    relation_to_mean = body_mass_g/mean_weight
  ) %>%
  dplyr::ungroup() %>% # ungroup removes lingering grouping
  dplyr::select(id, species, sex, year, relation_to_mean) %>%
  # mutate does not remove rows, unlike summarise, so we use select
  dplyr::arrange(dplyr::desc(relation_to_mean))
```

### Conditional operations with `ifelse`, `case_when` and `case_match`

- `ifelse` allows to implement conditional `mutate` operations, that consider information from other columns

```{r}
peng %>% dplyr::mutate(
  weight = ifelse(
    test = body_mass_g >= 4200, # is weight below or above mean weight?
    yes = "above mean",
    no = "below mean"
  )
)
```

- `ifelse` gets cumbersome easily. `dplyr::case_when` is more readable and scales much better for this application

```{r}
peng %>% dplyr::mutate(
  weight = dplyr::case_when(
    body_mass_g >= 4200 ~ "above mean", # the number of conditions is arbitrary
    body_mass_g < 4200  ~ "below mean",
    TRUE                ~ "unknown"     # TRUE catches all remaining cases
  )
)
```

- `dplyr::case_match` is similar, but unlike `dplyr::case_when` it does not check logical expressions, but matches by value

```{r}
peng %>% dplyr::mutate(
  island_rating = dplyr::case_match(
    island,
    "Torgersen" ~ "My favourite island",
    "Biscoe"    ~ "Overrated tourist trap",
    "Dream"     ~ "Lost my wallet there. 4/10"
  )
) %>%
  dplyr::group_by(island, island_rating) %>%
  dplyr::summarise() # here we use group_by+summarise only to show the result
```

### Switching between long and wide data with `pivot_longer` and `pivot_wider`

- For different applications or to simplify certain analysis or plotting operations data often has to be transformed from a **wide** to a **long** format or vice versa

![](assets/images/chapters/r-tidyverse/pivot_longer_wider.png){height=150px}

- A table in **wide** format has N key columns and N value columns
- A table in **long** format has N key columns, one descriptor column and one value column

***

- Here is an example of a wide dataset. It features information about the number of cars sold per year per brand at a dealership

```{r}
carsales <- tibble::tribble(
  ~brand, ~`2014`, ~`2015`, ~`2016`, ~`2017`,
  "BMW",  20,      25,      30,      45,
  "VW",   67,      40,     120,      55
)
carsales
```

- Wide format data becomes a problem, when the columns are semantically identical. This dataset is in wide format and we can not easily plot it
- We generally prefer data in long format, although it is more verbose with more duplication
- To transform this dataset to a long format, we can apply `tidyr::pivot_longer`

```{r}
carsales_long <- carsales %>% tidyr::pivot_longer(
  cols = tidyselect::num_range("", range = 2014:2017), # set of columns to transform
  names_to = "year",            # the name of the descriptor column we want
  names_transform = as.integer, # a transformation function to apply to the names
  values_to = "sales"           # the name of the value column we want
)
carsales_long
```

- Wide datasets are not always the wrong choice: The find application for example for adjacency matrices to represent graphs, covariance matrices or other pairwise statistics
- When data gets big, then wide formats can be significantly more efficient (e.g. for spatial data)
- So transform data from long to wide, we can use `tidyr::pivot_wider`

```{r}
carsales_wide <- carsales_long %>% tidyr::pivot_wider(
  id_cols = "brand",  # the set of id columns that should not be changed
  names_from = year,  # the descriptor column with the names of the new columns
  values_from = sales # the value column from which the values should be extracted
)
carsales_wide
```

### Exercise

1. Move the column `gear` to the first position of the mtcars dataset

```{r}

```

2. Make a new dataset `mtcars2` with the column `mpg` and an additional column `am_v`, which encodes the *transmission type* (`am`) as either `"manual"` or `"automatic"`

```{r}

```

3. Count the number of cars per *transmission type* (`am_v`) and *number of gears* (`gear`). Then transform the result to a wide format, with one column per *transmission type*.

```{r}

```

<details>
<summary>Possible solutions</summary>

```{r}
mtcars %>%
  dplyr::relocate(gear, .before = mpg) %>%
  tibble::as_tibble() # transforming the raw dataset to a tibble
                      # for better printing
```

```{r}
mtcars2 <- mtcars %>% dplyr::mutate(
  gear,
  am_v = dplyr::case_match(
    am,
    0 ~ "automatic",
    1 ~ "manual"
  )
) %>% tibble::as_tibble()
mtcars2
```

```{r}
mtcars2 %>%
  dplyr::group_by(am_v, gear) %>%
  dplyr::tally() %>% # dplyr::tally() is identical to
                     # dplyr::summarise(n = dplyr::n())
                     # it counts the number of entities in a group
  tidyr::pivot_wider(
    names_from = am_v,
    values_from = n
  )
```

</details>

## Combining tibbles with join operations

### Types of joins

Joins combine two datasets x and y based on key columns

- Mutating joins add columns from one dataset to the other
  - Left join: Take observations from x and add fitting information from y
  - Right join: Take observations from y and add fitting information from x
  - Inner join: Join the overlapping observations from x and y
  - Full join: Join all observations from x and y, even if information is missing
- Filtering joins remove observations from x based on their presence in y
  - Semi join: Keep every observation in x that is in y
  - Anti join: Keep every observation in x that is not in y

### A second dataset

- Contains additional variables for a subset of penguins
- Both datasets feature 300 penguins, but only with a partial overlap of individuals

```{r echo=FALSE}
bills <- readr::read_csv("assets/data/r-tidyverse/penguin_bills_2009.csv")
print(bills, n = 5)
```

### Left join

Take observations from x and add fitting information from y

![](assets/images/chapters/r-tidyverse/left_join.png){height=150px}

```{r}
dplyr::left_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"  # the key column by which to join
)
```

- Left joins are the most common join operation: Add information from y to the main dataset x

### Right join

Take observations from y and add fitting information from x

![](assets/images/chapters/r-tidyverse/right_join.png){height=150px}

```{r}
dplyr::right_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
) %>% dplyr::arrange(id)
```

- Right joins are almost identical to left joins -- only x and y have reversed roles

### Inner join

Join the overlapping observations from x and y

![](assets/images/chapters/r-tidyverse/inner_join.png){height=150px}

```{r}
dplyr::inner_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Inner joins are a fast and easy way to check, to which degree two dataset overlap

### Full join

Join all observations from x and y, even if information is missing

![](assets/images/chapters/r-tidyverse/full_join.png){height=150px}

```{r}
dplyr::full_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Full joins allow to preserve every bit of information

### Semi join

Keep every observation in x that is in y

![](assets/images/chapters/r-tidyverse/semi_join.png){height=150px}

```{r}
dplyr::semi_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Semi joins are underused operations to filter datasets

### Anti join

Keep every observation in x that is not in y

![](assets/images/chapters/r-tidyverse/anti_join.png){height=150px}

```{r}
dplyr::anti_join(
  x = peng,  # 300 observations
  y = bills, # 300 observations
  by = "id"
)
```

- Anti joins allow to quickly specify incomplete datasets and missing information



### Exercise 4

Consider the following additional dataset:

```{r}
gear_opinions <- tibble::tibble(gear = c(3, 5), opinion = c("boring", "wow"))
```

1. Add my opinions about gears to the `mtcars` dataset

```{r}

```

2. Remove all cars from the dataset for which I don't have an opinion

```{r}

```















### Possible Solutions 4

1. Add my opinions about gears to the `mtcars` dataset

```{r, eval=FALSE}
dplyr::left_join(mtcars, gear_opinions, by = "gear")
```

2. Remove all cars from the dataset for which I don't have an opinion

```{r, eval=FALSE}
dplyr::anti_join(mtcars, gear_opinions, by = "gear")
```
