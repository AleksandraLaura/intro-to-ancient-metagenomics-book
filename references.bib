@ARTICLE{Schuster2008-qx,
  title    = "Next-generation sequencing transforms today's biology",
  author   = "Schuster, Stephan C",
  journal  = "Nature methods",
  volume   =  5,
  number   =  1,
  pages    = "16--18",
  abstract = "A new generation of non-Sanger-based sequencing technologies has
              delivered on its promise of sequencing DNA at unprecedented speed,
              thereby enabling impressive scientific achievements and novel
              biological applications. However, before stepping into the
              limelight, next-generation sequencing had to overcome the inertia
              of a field that relied on Sanger-sequencing for 30 years.",
  month    =  jan,
  year     =  2008,
  url      = "http://dx.doi.org/10.1038/nmeth1156",
  doi      = "10.1038/nmeth1156",
  issn     = "1548-7105,1548-7091",
  language = "en",
  pmid     =  18165802
}

@ARTICLE{Shendure2008-fh,
  title    = "Next-generation {DNA} sequencing",
  author   = "Shendure, Jay and Ji, Hanlee",
  journal  = "Nature biotechnology",
  volume   =  26,
  number   =  10,
  pages    = "1135--1145",
  abstract = "DNA sequence represents a single format onto which a broad range
              of biological phenomena can be projected for high-throughput data
              collection. Over the past three years, massively parallel DNA
              sequencing platforms have become widely available, reducing the
              cost of DNA sequencing by over two orders of magnitude, and
              democratizing the field by putting the sequencing capacity of a
              major genome center in the hands of individual investigators.
              These new technologies are rapidly evolving, and near-term
              challenges include the development of robust protocols for
              generating sequencing libraries, building effective new approaches
              to data-analysis, and often a rethinking of experimental design.
              Next-generation DNA sequencing has the potential to dramatically
              accelerate biological and biomedical research, by enabling the
              comprehensive analysis of genomes, transcriptomes and interactomes
              to become inexpensive, routine and widespread, rather than
              requiring significant production-scale efforts.",
  month    =  oct,
  year     =  2008,
  url      = "http://dx.doi.org/10.1038/nbt1486",
  doi      = "10.1038/nbt1486",
  issn     = "1546-1696,1087-0156",
  language = "en",
  pmid     =  18846087
}

@ARTICLE{Slatko2018-hg,
  title    = "Overview of Next-Generation Sequencing Technologies",
  author   = "Slatko, Barton E and Gardner, Andrew F and Ausubel, Frederick M",
  journal  = "Current protocols in molecular biology / edited by Frederick M.
              Ausubel ... [et al.]",
  volume   =  122,
  number   =  1,
  pages    = "e59",
  abstract = "High throughput DNA sequencing methodology (next generation
              sequencing; NGS) has rapidly evolved over the past 15 years and
              new methods are continually being commercialized. As the
              technology develops, so do increases in the number of
              corresponding applications for basic and applied science. The
              purpose of this review is to provide a compendium of NGS
              methodologies and associated applications. Each brief discussion
              is followed by web links to the manufacturer and/or web-based
              visualizations. Keyword searches, such as with Google, may also
              provide helpful internet links and information. © 2018 by John
              Wiley \& Sons, Inc.",
  month    =  apr,
  year     =  2018,
  url      = "http://dx.doi.org/10.1002/cpmb.59",
  keywords = "NGS; Sanger sequencing; next-generation sequencing",
  doi      = "10.1002/cpmb.59",
  issn     = "1934-3647,1934-3639",
  pmc      = "PMC6020069",
  language = "en",
  pmid     =  29851291
}

@ARTICLE{Van_Dijk2014-ep,
  title    = "Ten years of next-generation sequencing technology",
  author   = "van Dijk, Erwin L and Auger, Hélène and Jaszczyszyn, Yan and
              Thermes, Claude",
  journal  = "Trends in genetics",
  volume   =  30,
  number   =  9,
  pages    = "418--426",
  abstract = "Ten years ago next-generation sequencing (NGS) technologies
              appeared on the market. During the past decade, tremendous
              progress has been made in terms of speed, read length, and
              throughput, along with a sharp reduction in per-base cost.
              Together, these advances democratized NGS and paved the way for
              the development of a large number of novel NGS applications in
              basic science as well as in translational research areas such as
              clinical diagnostics, agrigenomics, and forensic science. Here we
              provide an overview of the evolution of NGS and discuss the most
              significant improvements in sequencing technologies and library
              preparation protocols. We also explore the current landscape of
              NGS applications and provide a perspective for future
              developments.",
  month    =  sep,
  year     =  2014,
  url      = "http://dx.doi.org/10.1016/j.tig.2014.07.001",
  keywords = "ChIP-seq; DNA-seq; NGS library preparation; Next-generation
              sequencing (NGS); RNA-seq; genomics",
  doi      = "10.1016/j.tig.2014.07.001",
  issn     = "0168-9525",
  language = "en",
  pmid     =  25108476
}

@ARTICLE{Kircher2012-fg,
  title    = "Double indexing overcomes inaccuracies in multiplex sequencing on
              the Illumina platform",
  author   = "Kircher, Martin and Sawyer, Susanna and Meyer, Matthias",
  journal  = "Nucleic acids research",
  volume   =  40,
  number   =  1,
  pages    = "e3",
  abstract = "Due to the increasing throughput of current DNA sequencing
              instruments, sample multiplexing is necessary for making
              economical use of available sequencing capacities. A widely used
              multiplexing strategy for the Illumina Genome Analyzer utilizes
              sample-specific indexes, which are embedded in one of the library
              adapters. However, this and similar multiplex approaches come with
              a risk of sample misidentification. By introducing indexes into
              both library adapters (double indexing), we have developed a
              method that reveals the rate of sample misidentification within
              current multiplex sequencing experiments. With ~0.3\% these rates
              are orders of magnitude higher than expected and may severely
              confound applications in cancer genomics and other fields
              requiring accurate detection of rare variants. We identified the
              occurrence of mixed clusters on the flow as the predominant source
              of error. The accuracy of sample identification is further
              impaired if indexed oligonucleotides are cross-contaminated or if
              indexed libraries are amplified in bulk. Double-indexing
              eliminates these problems and increases both the scope and
              accuracy of multiplex sequencing on the Illumina platform.",
  month    =  jan,
  year     =  2012,
  url      = "http://dx.doi.org/10.1093/nar/gkr771",
  doi      = "10.1093/nar/gkr771",
  issn     = "1362-4962,0305-1048",
  pmc      = "PMC3245947",
  pmid     =  22021376
}

@ARTICLE{Meyer2010-qc,
  title    = "Illumina sequencing library preparation for highly multiplexed
              target capture and sequencing",
  author   = "Meyer, Matthias and Kircher, Martin",
  journal  = "Cold Spring Harbor protocols",
  volume   =  2010,
  number   =  6,
  pages    = "db.prot5448",
  abstract = "The large amount of DNA sequence data generated by high-throughput
              sequencing technologies often allows multiple samples to be
              sequenced in parallel on a single sequencing run. This is
              particularly true if subsets of the genome are studied rather than
              complete genomes. In recent years, target capture from sequencing
              libraries has largely replaced polymerase chain reaction (PCR) as
              the preferred method of target enrichment. Parallelizing target
              capture and sequencing for multiple samples requires the
              incorporation of sample-specific barcodes into sequencing
              libraries, which is necessary to trace back the sample source of
              each sequence. This protocol describes a fast and reliable method
              for the preparation of barcoded (``indexed'') sequencing libraries
              for Illumina's Genome Analyzer platform. The protocol avoids
              expensive commercial library preparation kits and can be performed
              in a 96-well plate setup using multi-channel pipettes, requiring
              not more than two or three days of lab work. Libraries can be
              prepared from any type of double-stranded DNA, even if present in
              subnanogram quantity.",
  month    =  jun,
  year     =  2010,
  url      = "http://dx.doi.org/10.1101/pdb.prot5448",
  doi      = "10.1101/pdb.prot5448",
  issn     = "1559-6095,1940-3402",
  pmid     =  20516186
}

@ARTICLE{Ma2019-lg,
  title    = "Analysis of error profiles in deep next-generation sequencing data",
  author   = "Ma, Xiaotu and Shao, Ying and Tian, Liqing and Flasch, Diane A and
              Mulder, Heather L and Edmonson, Michael N and Liu, Yu and Chen,
              Xiang and Newman, Scott and Nakitandwe, Joy and Li, Yongjin and
              Li, Benshang and Shen, Shuhong and Wang, Zhaoming and Shurtleff,
              Sheila and Robison, Leslie L and Levy, Shawn and Easton, John and
              Zhang, Jinghui",
  journal  = "Genome biology",
  volume   =  20,
  number   =  1,
  pages    =  50,
  abstract = "BACKGROUND: Sequencing errors are key confounding factors for
              detecting low-frequency genetic variants that are important for
              cancer molecular diagnosis, treatment, and surveillance using deep
              next-generation sequencing (NGS). However, there is a lack of
              comprehensive understanding of errors introduced at various steps
              of a conventional NGS workflow, such as sample handling, library
              preparation, PCR enrichment, and sequencing. In this study, we use
              current NGS technology to systematically investigate these
              questions. RESULTS: By evaluating read-specific error
              distributions, we discover that the substitution error rate can be
              computationally suppressed to 10-5 to 10-4, which is 10- to
              100-fold lower than generally considered achievable (10-3) in the
              current literature. We then quantify substitution errors
              attributable to sample handling, library preparation, enrichment
              PCR, and sequencing by using multiple deep sequencing datasets. We
              find that error rates differ by nucleotide substitution types,
              ranging from 10-5 for A>C/T>G, C>A/G>T, and C>G/G>C changes to
              10-4 for A>G/T>C changes. Furthermore, C>T/G>A errors exhibit
              strong sequence context dependency, sample-specific effects
              dominate elevated C>A/G>T errors, and target-enrichment PCR led to
              ~ 6-fold increase of overall error rate. We also find that more
              than 70\% of hotspot variants can be detected at 0.1 ~ 0.01\%
              frequency with the current NGS technology by applying in silico
              error suppression. CONCLUSIONS: We present the first comprehensive
              analysis of sequencing error sources in conventional NGS
              workflows. The error profiles revealed by our study highlight new
              directions for further improving NGS analysis accuracy both
              experimentally and computationally, ultimately enhancing the
              precision of deep sequencing.",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1186/s13059-019-1659-6",
  keywords = "Deep sequencing; Detection; Error rate; Hotspot mutation;
              Subclonal; Substitution",
  doi      = "10.1186/s13059-019-1659-6",
  issn     = "1465-6906",
  pmc      = "PMC6417284",
  language = "en",
  pmid     =  30867008
}
@UNPUBLISHED{Sinha2017-zo,
  title    = "Index switching causes “spreading-of-signal” among multiplexed
              samples in Illumina {HiSeq} 4000 {DNA} sequencing",
  author   = "Sinha, Rahul and Stanley, Geoff and Gulati, Gunsagar Singh and
              Ezran, Camille and Travaglini, Kyle Joseph and Wei, Eric and Chan,
              Charles Kwok Fai and Nabhan, Ahmad N and Su, Tianying and
              Morganti, Rachel Marie and Conley, Stephanie Diana and Chaib,
              Hassan and Red-Horse, Kristy and Longaker, Michael T and Snyder,
              Michael P and Krasnow, Mark A and Weissman, Irving L",
  journal  = "bioRxiv",
  pages    =  125724,
  abstract = "Illumina-based next generation sequencing (NGS) has accelerated
              biomedical discovery through its ability to generate thousands of
              gigabases of sequencing output per run at a fraction of the time
              and cost of conventional technologies. The process typically
              involves four basic steps: library preparation, cluster
              generation, sequencing, and data analysis. In 2015, a new
              chemistry of cluster generation was introduced in the newer
              Illumina machines (HiSeq 3000/4000/X Ten) called exclusion
              amplification (ExAmp), which was a fundamental shift from the
              earlier method of random cluster generation by bridge
              amplification on a non-patterned flow cell. The ExAmp chemistry,
              in conjunction with patterned flow cells containing nanowells at
              fixed locations, increases cluster density on the flow cell,
              thereby reducing the cost per run. It also increases sequence read
              quality, especially for longer read lengths (up to 150 base
              pairs). This advance has been widely adopted for genome sequencing
              because greater sequencing depth can be achieved for lower cost
              without compromising the quality of longer reads. We show that
              this promising chemistry is problematic, however, when
              multiplexing samples. We discovered that up to 5-10\% of
              sequencing reads (or signals) are incorrectly assigned from a
              given sample to other samples in a multiplexed pool. We provide
              evidence that this “spreading-of-signals” arises from low levels
              of free index primers present in the pool. These index primers can
              prime pooled library fragments at random via complementary 3′
              ends, and get extended by DNA polymerase, creating a new library
              molecule with a new index before binding to the patterned flow
              cell to generate a cluster for sequencing. This causes the
              resulting read from that cluster to be assigned to a different
              sample, causing the spread of signals within multiplexed samples.
              We show that low levels of free index primers persist after the
              most common library purification procedure recommended by
              Illumina, and that the amount of signal spreading among samples is
              proportional to the level of free index primer present in the
              library pool. This artifact causes homogenization and
              misclassification of cells in single cell RNA-seq experiments.
              Therefore, all data generated in this way must now be carefully
              re-examined to ensure that “spreading-of-signals” has not
              compromised data analysis and conclusions. Re-sequencing samples
              using an older technology that uses conventional bridge
              amplification for cluster generation, or improved library cleanup
              strategies to remove free index primers, can minimize or eliminate
              this signal spreading artifact.",
  month    =  apr,
  year     =  2017,
  url      = "http://dx.doi.org/10.1101/125724",
  doi      = "10.1101/125724",
  language = "en"
}

@ARTICLE{Van_der_Valk2019-to,
  title    = "Index hopping on the Illumina {HiseqX} platform and its
              consequences for ancient {DNA} studies",
  author   = "van der Valk, Tom and Vezzi, Francesco and Ormestad, Mattias and
              Dalén, Love and Guschanski, Katerina",
  journal  = "Molecular ecology resources",
  abstract = "The high-throughput capacities of the Illumina sequencing
              platforms and the possibility to label samples individually have
              encouraged wide use of sample multiplexing. However, this practice
              results in read misassignment (usually <1\%) across samples
              sequenced on the same lane. Alarmingly high rates of read
              misassignment of up to 10\% were reported for lllumina sequencing
              machines with exclusion amplification chemistry. This may make use
              of these platforms prohibitive, particularly in studies that rely
              on low-quantity and low-quality samples, such as historical and
              archaeological specimens. Here, we use barcodes, short sequences
              that are ligated to both ends of the DNA insert, to directly
              quantify the rate of index hopping in 100-year old
              museum-preserved gorilla (Gorilla beringei) samples. Correcting
              for multiple sources of noise, we identify on average 0.470\% of
              reads containing a hopped index. We show that sample-specific
              quantity of misassigned reads depends on the number of reads that
              any given sample contributes to the total sequencing pool, so that
              samples with few sequenced reads receive the greatest proportion
              of misassigned reads. This particularly affects ancient DNA
              samples, as these frequently differ in their DNA quantity and
              endogenous content. Through simulations we show that even low
              rates of index hopping, as reported here, can lead to biases in
              ancient DNA studies when multiplexing samples with vastly
              different quantities of endogenous material.",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1111/1755-0998.13009",
  keywords = "ancient DNA; index switching; multiplexing; museum specimens;
              next-generation sequencing; read misassignment",
  doi      = "10.1111/1755-0998.13009",
  issn     = "1755-0998,1755-098X",
  language = "en",
  pmid     =  30848092
}

@ARTICLE{Anagnostou2015-mz,
  title    = "When data sharing gets close to 100\%: what human paleogenetics
              can teach the open science movement",
  author   = "Anagnostou, Paolo and Capocasa, Marco and Milia, Nicola and Sanna,
              Emanuele and Battaggia, Cinzia and Luzi, Daniela and Destro Bisol,
              Giovanni",
  journal  = "PloS one",
  volume   =  10,
  number   =  3,
  pages    = "e0121409",
  abstract = "This study analyzes data sharing regarding mitochondrial, Y
              chromosomal and autosomal polymorphisms in a total of 162 papers
              on ancient human DNA published between 1988 and 2013. The
              estimated sharing rate was not far from totality (97.6\% ± 2.1\%)
              and substantially higher than observed in other fields of genetic
              research (evolutionary, medical and forensic genetics). Both a
              questionnaire-based survey and the examination of Journals'
              editorial policies suggest that this high sharing rate cannot be
              simply explained by the need to comply with stakeholders requests.
              Most data were made available through body text, but the use of
              primary databases increased in coincidence with the introduction
              of complete mitochondrial and next-generation sequencing methods.
              Our study highlights three important aspects. First, our results
              imply that researchers' awareness of the importance of openness
              and transparency for scientific progress may complement
              stakeholders' policies in achieving very high sharing rates.
              Second, widespread data sharing does not necessarily coincide with
              a prevalent use of practices which maximize data findability,
              accessibility, useability and preservation. A detailed look at the
              different ways in which data are released can be very useful to
              detect failures to adopt the best sharing modalities and
              understand how to correct them. Third and finally, the case of
              human paleogenetics tells us that a widespread awareness of the
              importance of Open Science may be important to build reliable
              scientific practices even in the presence of complex experimental
              challenges.",
  month    =  mar,
  year     =  2015,
  url      = "http://dx.doi.org/10.1371/journal.pone.0121409",
  doi      = "10.1371/journal.pone.0121409",
  pmc      = "PMC4370607",
  pmid     =  25799293,
  issn     = "1932-6203",
  language = "en"
}
@ARTICLE{Fellows_Yates2021-rp,
  title    = "Community-curated and standardised metadata of published ancient
              metagenomic samples with {AncientMetagenomeDir}",
  author   = "Fellows Yates, James A and Andrades Valtueña, Aida and Vågene,
              Åshild J and Cribdon, Becky and Velsko, Irina M and Borry, Maxime
              and Bravo-Lopez, Miriam J and Fernandez-Guerra, Antonio and Green,
              Eleanor J and Ramachandran, Shreya L and Heintzman, Peter D and
              Spyrou, Maria A and Hübner, Alexander and Gancz, Abigail S and
              Hider, Jessica and Allshouse, Aurora F and Zaro, Valentina and
              Warinner, Christina",
  journal  = "Scientific data",
  volume   =  8,
  number   =  1,
  pages    =  31,
  abstract = "Ancient DNA and RNA are valuable data sources for a wide range of
              disciplines. Within the field of ancient metagenomics, the number
              of published genetic datasets has risen dramatically in recent
              years, and tracking this data for reuse is particularly important
              for large-scale ecological and evolutionary studies of individual
              taxa and communities of both microbes and eukaryotes.
              AncientMetagenomeDir (archived at
              https://doi.org/10.5281/zenodo.3980833 ) is a collection of
              annotated metagenomic sample lists derived from published studies
              that provide basic, standardised metadata and accession numbers to
              allow rapid data retrieval from online repositories. These tables
              are community-curated and span multiple sub-disciplines to ensure
              adequate breadth and consensus in metadata definitions, as well as
              longevity of the database. Internal guidelines and automated
              checks facilitate compatibility with established sequence-read
              archives and term-ontologies, and ensure consistency and
              interoperability for future meta-analyses. This collection will
              also assist in standardising metadata reporting for future ancient
              metagenomic studies.",
  month    =  jan,
  year     =  2021,
  url      = "http://dx.doi.org/10.1038/s41597-021-00816-y",
  doi      = "10.1038/s41597-021-00816-y",
  pmid     =  33500403,
  issn     = "2052-4463",
  language = "en"
}
@ARTICLE{Kocher2021-vg,
  title    = "Ten millennia of hepatitis {B} virus evolution",
  author   = "Kocher, Arthur and Papac, Luka and Barquera, Rodrigo and Key,
              Felix M and Spyrou, Maria A and Hübler, Ron and Rohrlach, Adam B
              and Aron, Franziska and Stahl, Raphaela and Wissgott, Antje and
              van Bömmel, Florian and Pfefferkorn, Maria and Mittnik, Alissa and
              Villalba-Mouco, Vanessa and Neumann, Gunnar U and Rivollat, Maïté
              and van de Loosdrecht, Marieke S and Majander, Kerttu and
              Tukhbatova, Rezeda I and Musralina, Lyazzat and Ghalichi, Ayshin
              and Penske, Sandra and Sabin, Susanna and Michel, Megan and
              Gretzinger, Joscha and Nelson, Elizabeth A and Ferraz, Tiago and
              Nägele, Kathrin and Parker, Cody and Keller, Marcel and Guevara,
              Evelyn K and Feldman, Michal and Eisenmann, Stefanie and
              Skourtanioti, Eirini and Giffin, Karen and Gnecchi-Ruscone, Guido
              Alberto and Friederich, Susanne and Schimmenti, Vittoria and
              Khartanovich, Valery and Karapetian, Marina K and Chaplygin,
              Mikhail S and Kufterin, Vladimir V and Khokhlov, Aleksandr A and
              Chizhevsky, Andrey A and Stashenkov, Dmitry A and Kochkina, Anna F
              and Tejedor-Rodríguez, Cristina and de Lagrán, Íñigo
              García-Martínez and Arcusa-Magallón, Héctor and Garrido-Pena,
              Rafael and Royo-Guillén, José Ignacio and Nováček, Jan and
              Rottier, Stéphane and Kacki, Sacha and Saintot, Sylvie and
              Kaverzneva, Elena and Belinskiy, Andrej B and Velemínský, Petr and
              Limburský, Petr and Kostka, Michal and Loe, Louise and Popescu,
              Elizabeth and Clarke, Rachel and Lyons, Alice and Mortimer,
              Richard and Sajantila, Antti and de Armas, Yadira Chinique and
              Hernandez Godoy, Silvia Teresita and Hernández-Zaragoza, Diana I
              and Pearson, Jessica and Binder, Didier and Lefranc, Philippe and
              Kantorovich, Anatoly R and Maslov, Vladimir E and Lai, Luca and
              Zoledziewska, Magdalena and Beckett, Jessica F and Langová,
              Michaela and Danielisová, Alžběta and Ingman, Tara and Atiénzar,
              Gabriel García and de Miguel Ibáñez, Maria Paz and Romero,
              Alejandro and Sperduti, Alessandra and Beckett, Sophie and Salter,
              Susannah J and Zilivinskaya, Emma D and Vasil'ev, Dmitry V and von
              Heyking, Kristin and Burger, Richard L and Salazar, Lucy C and
              Amkreutz, Luc and Navruzbekov, Masnav and Rosenstock, Eva and
              Alonso-Fernández, Carmen and Slavchev, Vladimir and Kalmykov,
              Alexey A and Atabiev, Biaslan Ch and Batieva, Elena and Calmet,
              Micaela Alvarez and Llamas, Bastien and Schultz, Michael and
              Krauß, Raiko and Jiménez-Echevarría, Javier and Francken, Michael
              and Shnaider, Svetlana and de Knijff, Peter and Altena, Eveline
              and Van de Vijver, Katrien and Fehren-Schmitz, Lars and Tung,
              Tiffiny A and Lösch, Sandra and Dobrovolskaya, Maria and Makarov,
              Nikolaj and Read, Chris and Van Twest, Melanie and Sagona, Claudia
              and Ramsl, Peter C and Akar, Murat and Yener, K Aslihan and
              Ballestero, Eduardo Carmona and Cucca, Francesco and Mazzarello,
              Vittorio and Utrilla, Pilar and Rademaker, Kurt and
              Fernández-Domínguez, Eva and Baird, Douglas and Semal, Patrick and
              Márquez-Morfín, Lourdes and Roksandic, Mirjana and Steiner, Hubert
              and Salazar-García, Domingo Carlos and Shishlina, Natalia and
              Erdal, Yilmaz Selim and Hallgren, Fredrik and Boyadzhiev, Yavor
              and Boyadzhiev, Kamen and Küßner, Mario and Sayer, Duncan and
              Onkamo, Päivi and Skeates, Robin and Rojo-Guerra, Manuel and
              Buzhilova, Alexandra and Khussainova, Elmira and Djansugurova,
              Leyla B and Beisenov, Arman Z and Samashev, Zainolla and Massy,
              Ken and Mannino, Marcello and Moiseyev, Vyacheslav and Mannermaa,
              Kristiina and Balanovsky, Oleg and Deguilloux, Marie-France and
              Reinhold, Sabine and Hansen, Svend and Kitov, Egor P and Dobeš,
              Miroslav and Ernée, Michal and Meller, Harald and Alt, Kurt W and
              Prüfer, Kay and Warinner, Christina and Schiffels, Stephan and
              Stockhammer, Philipp W and Bos, Kirsten and Posth, Cosimo and
              Herbig, Alexander and Haak, Wolfgang and Krause, Johannes and
              Kühnert, Denise",
  journal  = "Science",
  volume   =  374,
  number   =  6564,
  pages    = "182--188",
  abstract = "[Figure: see text].",
  month    =  oct,
  year     =  2021,
  url      = "http://dx.doi.org/10.1126/science.abi5658",
  doi      = "10.1126/science.abi5658",
  pmid     =  34618559,
  issn     = "0036-8075,1095-9203",
  language = "en"
}

@ARTICLE{Fellows_Yates2021-jl,
  title     = "Reproducible, portable, and efficient ancient genome
               reconstruction with nf-core/eager",
  author    = "Fellows Yates, James A and Lamnidis, Thiseas C and Borry, Maxime
               and Andrades Valtueña, Aida and Fagernäs, Zandra and Clayton,
               Stephen and Garcia, Maxime U and Neukamm, Judith and Peltzer,
               Alexander",
  journal   = "PeerJ",
  publisher = "PeerJ Inc.",
  volume    =  9,
  pages     = "e10947",
  abstract  = "The broadening utilisation of ancient DNA to address
               archaeological, palaeontological, and biological questions is
               resulting in a rising diversity in the size of laboratories and
               scale of analyses being performed. In the context of this
               heterogeneous landscape, we present an advanced, and entirely
               redesigned and extended version of the EAGER pipeline for the
               analysis of ancient genomic data. This Nextflow pipeline aims to
               address three main themes: accessibility and adaptability to
               different computing configurations, reproducibility to ensure
               robust analytical standards, and updating the pipeline to the
               latest routine ancient genomic practices. The new version of
               EAGER has been developed within the nf-core initiative to ensure
               high-quality software development and maintenance support;
               contributing to a long-term life-cycle for the pipeline.
               nf-core/eager will assist in ensuring that a wider range of
               ancient DNA analyses can be applied by a diverse range of
               research groups and fields.",
  month     =  mar,
  year      =  2021,
  url       = "http://dx.doi.org/10.7717/peerj.10947",
  keywords  = "Bioinformatics; Palaeogenomics; Ancient DNA; Pipeline; Nextflow;
               Reproducibility; Genomics; Metagenomics",
  doi       = "10.7717/peerj.10947",
  pmc       = "PMC7977378",
  pmid      =  33777521,
  issn      = "2167-8359",
  language  = "en"
}

@ARTICLE{Schubert2014-ps,
  title    = "Characterization of ancient and modern genomes by {SNP} detection
              and phylogenomic and metagenomic analysis using {PALEOMIX}",
  author   = "Schubert, Mikkel and Ermini, Luca and Der Sarkissian, Clio and
              Jónsson, Hákon and Ginolhac, Aurélien and Schaefer, Robert and
              Martin, Michael D and Fernández, Ruth and Kircher, Martin and
              McCue, Molly and Willerslev, Eske and Orlando, Ludovic",
  journal  = "Nature protocols",
  volume   =  9,
  number   =  5,
  pages    = "1056--1082",
  abstract = "Next-generation sequencing technologies have revolutionized the
              field of paleogenomics, allowing the reconstruction of complete
              ancient genomes and their comparison with modern references.
              However, this requires the processing of vast amounts of data and
              involves a large number of steps that use a variety of
              computational tools. Here we present PALEOMIX
              (http://geogenetics.ku.dk/publications/paleomix), a flexible and
              user-friendly pipeline applicable to both modern and ancient
              genomes, which largely automates the in silico analyses behind
              whole-genome resequencing. Starting with next-generation
              sequencing reads, PALEOMIX carries out adapter removal, mapping
              against reference genomes, PCR duplicate removal, characterization
              of and compensation for postmortem damage, SNP calling and
              maximum-likelihood phylogenomic inference, and it profiles the
              metagenomic contents of the samples. As such, PALEOMIX allows for
              a series of potential applications in paleogenomics, comparative
              genomics and metagenomics. Applying the PALEOMIX pipeline to the
              three ancient and seven modern Phytophthora infestans genomes as
              described here takes 5 d using a 16-core server.",
  month    =  may,
  year     =  2014,
  url      = "http://dx.doi.org/10.1038/nprot.2014.063",
  doi      = "10.1038/nprot.2014.063",
  pmid     =  24722405,
  issn     = "1754-2189,1750-2799"
}

@UNPUBLISHED{Pochon2022-hj,
  title    = "{aMeta}: an accurate and memory-efficient ancient Metagenomic
              profiling workflow",
  author   = "Pochon, Zoé and Bergfeldt, Nora and Kırdök, Emrah and Vicente,
              Mário and Naidoo, Thijessen and van der Valk, Tom and Ezgi
              Altınışık, N and Krzewińska, Maja and Dalen, Love and Götherström,
              Anders and Mirabello, Claudio and Unneberg, Per and Oskolkov,
              Nikolay",
  journal  = "bioRxiv",
  pages    = "2022.10.03.510579",
  abstract = "Analysis of microbial data from archaeological samples is a
              rapidly growing field with a great potential for understanding
              ancient environments, lifestyles and disease spread in the past.
              However, high error rates have been a long-standing challenge in
              ancient metagenomics analysis. This is also complicated by a
              limited choice of ancient microbiome specific computational
              frameworks that meet the growing computational demands of the
              field. Here, we propose aMeta, an accurate ancient Metagenomic
              profiling workflow designed primarily to minimize the amount of
              false discoveries and computer memory requirements. Using
              simulated ancient metagenomic samples, we benchmark aMeta against
              a current state-of-the-art workflow, and demonstrate its superior
              sensitivity and specificity in both microbial detection and
              authentication, as well as substantially lower usage of computer
              memory. aMeta is implemented as a Snakemake workflow to facilitate
              use and reproducibility. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  month    =  oct,
  year     =  2022,
  url      = "https://www.biorxiv.org/content/10.1101/2022.10.03.510579v1",
  doi      = "10.1101/2022.10.03.510579",
  language = "en"
}
