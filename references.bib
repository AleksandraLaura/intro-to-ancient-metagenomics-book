@ARTICLE{Schuster2008-qx,
  title    = "Next-generation sequencing transforms today's biology",
  author   = "Schuster, Stephan C",
  journal  = "Nature methods",
  volume   =  5,
  number   =  1,
  pages    = "16--18",
  abstract = "A new generation of non-Sanger-based sequencing technologies has
              delivered on its promise of sequencing DNA at unprecedented speed,
              thereby enabling impressive scientific achievements and novel
              biological applications. However, before stepping into the
              limelight, next-generation sequencing had to overcome the inertia
              of a field that relied on Sanger-sequencing for 30 years.",
  month    =  jan,
  year     =  2008,
  url      = "http://dx.doi.org/10.1038/nmeth1156",
  doi      = "10.1038/nmeth1156",
  issn     = "1548-7105,1548-7091",
  language = "en",
  pmid     =  18165802
}

@ARTICLE{Shendure2008-fh,
  title    = "Next-generation {DNA} sequencing",
  author   = "Shendure, Jay and Ji, Hanlee",
  journal  = "Nature biotechnology",
  volume   =  26,
  number   =  10,
  pages    = "1135--1145",
  abstract = "DNA sequence represents a single format onto which a broad range
              of biological phenomena can be projected for high-throughput data
              collection. Over the past three years, massively parallel DNA
              sequencing platforms have become widely available, reducing the
              cost of DNA sequencing by over two orders of magnitude, and
              democratizing the field by putting the sequencing capacity of a
              major genome center in the hands of individual investigators.
              These new technologies are rapidly evolving, and near-term
              challenges include the development of robust protocols for
              generating sequencing libraries, building effective new approaches
              to data-analysis, and often a rethinking of experimental design.
              Next-generation DNA sequencing has the potential to dramatically
              accelerate biological and biomedical research, by enabling the
              comprehensive analysis of genomes, transcriptomes and interactomes
              to become inexpensive, routine and widespread, rather than
              requiring significant production-scale efforts.",
  month    =  oct,
  year     =  2008,
  url      = "http://dx.doi.org/10.1038/nbt1486",
  doi      = "10.1038/nbt1486",
  issn     = "1546-1696,1087-0156",
  language = "en",
  pmid     =  18846087
}

@ARTICLE{Slatko2018-hg,
  title    = "Overview of Next-Generation Sequencing Technologies",
  author   = "Slatko, Barton E and Gardner, Andrew F and Ausubel, Frederick M",
  journal  = "Current protocols in molecular biology / edited by Frederick M.
              Ausubel ... [et al.]",
  volume   =  122,
  number   =  1,
  pages    = "e59",
  abstract = "High throughput DNA sequencing methodology (next generation
              sequencing; NGS) has rapidly evolved over the past 15 years and
              new methods are continually being commercialized. As the
              technology develops, so do increases in the number of
              corresponding applications for basic and applied science. The
              purpose of this review is to provide a compendium of NGS
              methodologies and associated applications. Each brief discussion
              is followed by web links to the manufacturer and/or web-based
              visualizations. Keyword searches, such as with Google, may also
              provide helpful internet links and information. © 2018 by John
              Wiley \& Sons, Inc.",
  month    =  apr,
  year     =  2018,
  url      = "http://dx.doi.org/10.1002/cpmb.59",
  keywords = "NGS; Sanger sequencing; next-generation sequencing",
  doi      = "10.1002/cpmb.59",
  issn     = "1934-3647,1934-3639",
  pmc      = "PMC6020069",
  language = "en",
  pmid     =  29851291
}

@ARTICLE{Van_Dijk2014-ep,
  title    = "Ten years of next-generation sequencing technology",
  author   = "van Dijk, Erwin L and Auger, Hélène and Jaszczyszyn, Yan and
              Thermes, Claude",
  journal  = "Trends in genetics",
  volume   =  30,
  number   =  9,
  pages    = "418--426",
  abstract = "Ten years ago next-generation sequencing (NGS) technologies
              appeared on the market. During the past decade, tremendous
              progress has been made in terms of speed, read length, and
              throughput, along with a sharp reduction in per-base cost.
              Together, these advances democratized NGS and paved the way for
              the development of a large number of novel NGS applications in
              basic science as well as in translational research areas such as
              clinical diagnostics, agrigenomics, and forensic science. Here we
              provide an overview of the evolution of NGS and discuss the most
              significant improvements in sequencing technologies and library
              preparation protocols. We also explore the current landscape of
              NGS applications and provide a perspective for future
              developments.",
  month    =  sep,
  year     =  2014,
  url      = "http://dx.doi.org/10.1016/j.tig.2014.07.001",
  keywords = "ChIP-seq; DNA-seq; NGS library preparation; Next-generation
              sequencing (NGS); RNA-seq; genomics",
  doi      = "10.1016/j.tig.2014.07.001",
  issn     = "0168-9525",
  language = "en",
  pmid     =  25108476
}

@ARTICLE{Kircher2012-fg,
  title    = "Double indexing overcomes inaccuracies in multiplex sequencing on
              the Illumina platform",
  author   = "Kircher, Martin and Sawyer, Susanna and Meyer, Matthias",
  journal  = "Nucleic acids research",
  volume   =  40,
  number   =  1,
  pages    = "e3",
  abstract = "Due to the increasing throughput of current DNA sequencing
              instruments, sample multiplexing is necessary for making
              economical use of available sequencing capacities. A widely used
              multiplexing strategy for the Illumina Genome Analyzer utilizes
              sample-specific indexes, which are embedded in one of the library
              adapters. However, this and similar multiplex approaches come with
              a risk of sample misidentification. By introducing indexes into
              both library adapters (double indexing), we have developed a
              method that reveals the rate of sample misidentification within
              current multiplex sequencing experiments. With ~0.3\% these rates
              are orders of magnitude higher than expected and may severely
              confound applications in cancer genomics and other fields
              requiring accurate detection of rare variants. We identified the
              occurrence of mixed clusters on the flow as the predominant source
              of error. The accuracy of sample identification is further
              impaired if indexed oligonucleotides are cross-contaminated or if
              indexed libraries are amplified in bulk. Double-indexing
              eliminates these problems and increases both the scope and
              accuracy of multiplex sequencing on the Illumina platform.",
  month    =  jan,
  year     =  2012,
  url      = "http://dx.doi.org/10.1093/nar/gkr771",
  doi      = "10.1093/nar/gkr771",
  issn     = "1362-4962,0305-1048",
  pmc      = "PMC3245947",
  pmid     =  22021376
}

@ARTICLE{Meyer2010-qc,
  title    = "Illumina sequencing library preparation for highly multiplexed
              target capture and sequencing",
  author   = "Meyer, Matthias and Kircher, Martin",
  journal  = "Cold Spring Harbor protocols",
  volume   =  2010,
  number   =  6,
  pages    = "db.prot5448",
  abstract = "The large amount of DNA sequence data generated by high-throughput
              sequencing technologies often allows multiple samples to be
              sequenced in parallel on a single sequencing run. This is
              particularly true if subsets of the genome are studied rather than
              complete genomes. In recent years, target capture from sequencing
              libraries has largely replaced polymerase chain reaction (PCR) as
              the preferred method of target enrichment. Parallelizing target
              capture and sequencing for multiple samples requires the
              incorporation of sample-specific barcodes into sequencing
              libraries, which is necessary to trace back the sample source of
              each sequence. This protocol describes a fast and reliable method
              for the preparation of barcoded (``indexed'') sequencing libraries
              for Illumina's Genome Analyzer platform. The protocol avoids
              expensive commercial library preparation kits and can be performed
              in a 96-well plate setup using multi-channel pipettes, requiring
              not more than two or three days of lab work. Libraries can be
              prepared from any type of double-stranded DNA, even if present in
              subnanogram quantity.",
  month    =  jun,
  year     =  2010,
  url      = "http://dx.doi.org/10.1101/pdb.prot5448",
  doi      = "10.1101/pdb.prot5448",
  issn     = "1559-6095,1940-3402",
  pmid     =  20516186
}

@ARTICLE{Ma2019-lg,
  title    = "Analysis of error profiles in deep next-generation sequencing data",
  author   = "Ma, Xiaotu and Shao, Ying and Tian, Liqing and Flasch, Diane A and
              Mulder, Heather L and Edmonson, Michael N and Liu, Yu and Chen,
              Xiang and Newman, Scott and Nakitandwe, Joy and Li, Yongjin and
              Li, Benshang and Shen, Shuhong and Wang, Zhaoming and Shurtleff,
              Sheila and Robison, Leslie L and Levy, Shawn and Easton, John and
              Zhang, Jinghui",
  journal  = "Genome biology",
  volume   =  20,
  number   =  1,
  pages    =  50,
  abstract = "BACKGROUND: Sequencing errors are key confounding factors for
              detecting low-frequency genetic variants that are important for
              cancer molecular diagnosis, treatment, and surveillance using deep
              next-generation sequencing (NGS). However, there is a lack of
              comprehensive understanding of errors introduced at various steps
              of a conventional NGS workflow, such as sample handling, library
              preparation, PCR enrichment, and sequencing. In this study, we use
              current NGS technology to systematically investigate these
              questions. RESULTS: By evaluating read-specific error
              distributions, we discover that the substitution error rate can be
              computationally suppressed to 10-5 to 10-4, which is 10- to
              100-fold lower than generally considered achievable (10-3) in the
              current literature. We then quantify substitution errors
              attributable to sample handling, library preparation, enrichment
              PCR, and sequencing by using multiple deep sequencing datasets. We
              find that error rates differ by nucleotide substitution types,
              ranging from 10-5 for A>C/T>G, C>A/G>T, and C>G/G>C changes to
              10-4 for A>G/T>C changes. Furthermore, C>T/G>A errors exhibit
              strong sequence context dependency, sample-specific effects
              dominate elevated C>A/G>T errors, and target-enrichment PCR led to
              ~ 6-fold increase of overall error rate. We also find that more
              than 70\% of hotspot variants can be detected at 0.1 ~ 0.01\%
              frequency with the current NGS technology by applying in silico
              error suppression. CONCLUSIONS: We present the first comprehensive
              analysis of sequencing error sources in conventional NGS
              workflows. The error profiles revealed by our study highlight new
              directions for further improving NGS analysis accuracy both
              experimentally and computationally, ultimately enhancing the
              precision of deep sequencing.",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1186/s13059-019-1659-6",
  keywords = "Deep sequencing; Detection; Error rate; Hotspot mutation;
              Subclonal; Substitution",
  doi      = "10.1186/s13059-019-1659-6",
  issn     = "1465-6906",
  pmc      = "PMC6417284",
  language = "en",
  pmid     =  30867008
}
@UNPUBLISHED{Sinha2017-zo,
  title    = "Index switching causes “spreading-of-signal” among multiplexed
              samples in Illumina {HiSeq} 4000 {DNA} sequencing",
  author   = "Sinha, Rahul and Stanley, Geoff and Gulati, Gunsagar Singh and
              Ezran, Camille and Travaglini, Kyle Joseph and Wei, Eric and Chan,
              Charles Kwok Fai and Nabhan, Ahmad N and Su, Tianying and
              Morganti, Rachel Marie and Conley, Stephanie Diana and Chaib,
              Hassan and Red-Horse, Kristy and Longaker, Michael T and Snyder,
              Michael P and Krasnow, Mark A and Weissman, Irving L",
  journal  = "bioRxiv",
  pages    =  125724,
  abstract = "Illumina-based next generation sequencing (NGS) has accelerated
              biomedical discovery through its ability to generate thousands of
              gigabases of sequencing output per run at a fraction of the time
              and cost of conventional technologies. The process typically
              involves four basic steps: library preparation, cluster
              generation, sequencing, and data analysis. In 2015, a new
              chemistry of cluster generation was introduced in the newer
              Illumina machines (HiSeq 3000/4000/X Ten) called exclusion
              amplification (ExAmp), which was a fundamental shift from the
              earlier method of random cluster generation by bridge
              amplification on a non-patterned flow cell. The ExAmp chemistry,
              in conjunction with patterned flow cells containing nanowells at
              fixed locations, increases cluster density on the flow cell,
              thereby reducing the cost per run. It also increases sequence read
              quality, especially for longer read lengths (up to 150 base
              pairs). This advance has been widely adopted for genome sequencing
              because greater sequencing depth can be achieved for lower cost
              without compromising the quality of longer reads. We show that
              this promising chemistry is problematic, however, when
              multiplexing samples. We discovered that up to 5-10\% of
              sequencing reads (or signals) are incorrectly assigned from a
              given sample to other samples in a multiplexed pool. We provide
              evidence that this “spreading-of-signals” arises from low levels
              of free index primers present in the pool. These index primers can
              prime pooled library fragments at random via complementary 3′
              ends, and get extended by DNA polymerase, creating a new library
              molecule with a new index before binding to the patterned flow
              cell to generate a cluster for sequencing. This causes the
              resulting read from that cluster to be assigned to a different
              sample, causing the spread of signals within multiplexed samples.
              We show that low levels of free index primers persist after the
              most common library purification procedure recommended by
              Illumina, and that the amount of signal spreading among samples is
              proportional to the level of free index primer present in the
              library pool. This artifact causes homogenization and
              misclassification of cells in single cell RNA-seq experiments.
              Therefore, all data generated in this way must now be carefully
              re-examined to ensure that “spreading-of-signals” has not
              compromised data analysis and conclusions. Re-sequencing samples
              using an older technology that uses conventional bridge
              amplification for cluster generation, or improved library cleanup
              strategies to remove free index primers, can minimize or eliminate
              this signal spreading artifact.",
  month    =  apr,
  year     =  2017,
  url      = "http://dx.doi.org/10.1101/125724",
  doi      = "10.1101/125724",
  language = "en"
}

@ARTICLE{Van_der_Valk2019-to,
  title    = "Index hopping on the Illumina {HiseqX} platform and its
              consequences for ancient {DNA} studies",
  author   = "van der Valk, Tom and Vezzi, Francesco and Ormestad, Mattias and
              Dalén, Love and Guschanski, Katerina",
  journal  = "Molecular ecology resources",
  abstract = "The high-throughput capacities of the Illumina sequencing
              platforms and the possibility to label samples individually have
              encouraged wide use of sample multiplexing. However, this practice
              results in read misassignment (usually <1\%) across samples
              sequenced on the same lane. Alarmingly high rates of read
              misassignment of up to 10\% were reported for lllumina sequencing
              machines with exclusion amplification chemistry. This may make use
              of these platforms prohibitive, particularly in studies that rely
              on low-quantity and low-quality samples, such as historical and
              archaeological specimens. Here, we use barcodes, short sequences
              that are ligated to both ends of the DNA insert, to directly
              quantify the rate of index hopping in 100-year old
              museum-preserved gorilla (Gorilla beringei) samples. Correcting
              for multiple sources of noise, we identify on average 0.470\% of
              reads containing a hopped index. We show that sample-specific
              quantity of misassigned reads depends on the number of reads that
              any given sample contributes to the total sequencing pool, so that
              samples with few sequenced reads receive the greatest proportion
              of misassigned reads. This particularly affects ancient DNA
              samples, as these frequently differ in their DNA quantity and
              endogenous content. Through simulations we show that even low
              rates of index hopping, as reported here, can lead to biases in
              ancient DNA studies when multiplexing samples with vastly
              different quantities of endogenous material.",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1111/1755-0998.13009",
  keywords = "ancient DNA; index switching; multiplexing; museum specimens;
              next-generation sequencing; read misassignment",
  doi      = "10.1111/1755-0998.13009",
  issn     = "1755-0998,1755-098X",
  language = "en",
  pmid     =  30848092
}

@ARTICLE{Ju2006-cl,
  title    = "Four-color {DNA} sequencing by synthesis using cleavable
              fluorescent nucleotide reversible terminators",
  author   = "Ju, Jingyue and Kim, Dae Hyun and Bi, Lanrong and Meng, Qinglin
              and Bai, Xiaopeng and Li, Zengmin and Li, Xiaoxu and Marma, Mong
              Sano and Shi, Shundi and Wu, Jian and Edwards, John R and Romu,
              Aireen and Turro, Nicholas J",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  103,
  number   =  52,
  pages    = "19635--19640",
  abstract = "DNA sequencing by synthesis (SBS) on a solid surface during
              polymerase reaction offers a paradigm to decipher DNA sequences.
              We report here the construction of such a DNA sequencing system
              using molecular engineering approaches. In this approach, four
              nucleotides (A, C, G, T) are modified as reversible terminators by
              attaching a cleavable fluorophore to the base and capping the
              3'-OH group with a small chemically reversible moiety so that they
              are still recognized by DNA polymerase as substrates. We found
              that an allyl moiety can be used successfully as a linker to
              tether a fluorophore to 3'-O-allyl-modified nucleotides, forming
              chemically cleavable fluorescent nucleotide reversible
              terminators, 3'-O-allyl-dNTPs-allyl-fluorophore, for application
              in SBS. The fluorophore and the 3'-O-allyl group on a DNA
              extension product, which is generated by incorporating
              3'-O-allyl-dNTPs-allyl-fluorophore in a polymerase reaction, are
              removed simultaneously in 30 s by Pd-catalyzed deallylation in
              aqueous buffer solution. This one-step dual-deallylation reaction
              thus allows the reinitiation of the polymerase reaction and
              increases the SBS efficiency. DNA templates consisting of
              homopolymer regions were accurately sequenced by using this class
              of fluorescent nucleotide analogues on a DNA chip and a four-color
              fluorescent scanner.",
  month    =  dec,
  year     =  2006,
  url      = "http://dx.doi.org/10.1073/pnas.0609513103",
  doi      = "10.1073/pnas.0609513103",
  pmc      = "PMC1702316",
  pmid     =  17170132,
  issn     = "0027-8424",
  language = "en"
}

@ARTICLE{Anagnostou2015-mz,
  title    = "When data sharing gets close to 100\%: what human paleogenetics
              can teach the open science movement",
  author   = "Anagnostou, Paolo and Capocasa, Marco and Milia, Nicola and Sanna,
              Emanuele and Battaggia, Cinzia and Luzi, Daniela and Destro Bisol,
              Giovanni",
  journal  = "PloS one",
  volume   =  10,
  number   =  3,
  pages    = "e0121409",
  abstract = "This study analyzes data sharing regarding mitochondrial, Y
              chromosomal and autosomal polymorphisms in a total of 162 papers
              on ancient human DNA published between 1988 and 2013. The
              estimated sharing rate was not far from totality (97.6\% ± 2.1\%)
              and substantially higher than observed in other fields of genetic
              research (evolutionary, medical and forensic genetics). Both a
              questionnaire-based survey and the examination of Journals'
              editorial policies suggest that this high sharing rate cannot be
              simply explained by the need to comply with stakeholders requests.
              Most data were made available through body text, but the use of
              primary databases increased in coincidence with the introduction
              of complete mitochondrial and next-generation sequencing methods.
              Our study highlights three important aspects. First, our results
              imply that researchers' awareness of the importance of openness
              and transparency for scientific progress may complement
              stakeholders' policies in achieving very high sharing rates.
              Second, widespread data sharing does not necessarily coincide with
              a prevalent use of practices which maximize data findability,
              accessibility, useability and preservation. A detailed look at the
              different ways in which data are released can be very useful to
              detect failures to adopt the best sharing modalities and
              understand how to correct them. Third and finally, the case of
              human paleogenetics tells us that a widespread awareness of the
              importance of Open Science may be important to build reliable
              scientific practices even in the presence of complex experimental
              challenges.",
  month    =  mar,
  year     =  2015,
  url      = "http://dx.doi.org/10.1371/journal.pone.0121409",
  doi      = "10.1371/journal.pone.0121409",
  pmc      = "PMC4370607",
  pmid     =  25799293,
  issn     = "1932-6203",
  language = "en"
}
@ARTICLE{Fellows_Yates2021-rp,
  title    = "Community-curated and standardised metadata of published ancient
              metagenomic samples with {AncientMetagenomeDir}",
  author   = "Fellows Yates, James A and Andrades Valtueña, Aida and Vågene,
              Åshild J and Cribdon, Becky and Velsko, Irina M and Borry, Maxime
              and Bravo-Lopez, Miriam J and Fernandez-Guerra, Antonio and Green,
              Eleanor J and Ramachandran, Shreya L and Heintzman, Peter D and
              Spyrou, Maria A and Hübner, Alexander and Gancz, Abigail S and
              Hider, Jessica and Allshouse, Aurora F and Zaro, Valentina and
              Warinner, Christina",
  journal  = "Scientific data",
  volume   =  8,
  number   =  1,
  pages    =  31,
  abstract = "Ancient DNA and RNA are valuable data sources for a wide range of
              disciplines. Within the field of ancient metagenomics, the number
              of published genetic datasets has risen dramatically in recent
              years, and tracking this data for reuse is particularly important
              for large-scale ecological and evolutionary studies of individual
              taxa and communities of both microbes and eukaryotes.
              AncientMetagenomeDir (archived at
              https://doi.org/10.5281/zenodo.3980833 ) is a collection of
              annotated metagenomic sample lists derived from published studies
              that provide basic, standardised metadata and accession numbers to
              allow rapid data retrieval from online repositories. These tables
              are community-curated and span multiple sub-disciplines to ensure
              adequate breadth and consensus in metadata definitions, as well as
              longevity of the database. Internal guidelines and automated
              checks facilitate compatibility with established sequence-read
              archives and term-ontologies, and ensure consistency and
              interoperability for future meta-analyses. This collection will
              also assist in standardising metadata reporting for future ancient
              metagenomic studies.",
  month    =  jan,
  year     =  2021,
  url      = "http://dx.doi.org/10.1038/s41597-021-00816-y",
  doi      = "10.1038/s41597-021-00816-y",
  pmid     =  33500403,
  issn     = "2052-4463",
  language = "en"
}
@ARTICLE{Kocher2021-vg,
  title    = "Ten millennia of hepatitis {B} virus evolution",
  author   = "Kocher, Arthur and Papac, Luka and Barquera, Rodrigo and Key,
              Felix M and Spyrou, Maria A and Hübler, Ron and Rohrlach, Adam B
              and Aron, Franziska and Stahl, Raphaela and Wissgott, Antje and
              van Bömmel, Florian and Pfefferkorn, Maria and Mittnik, Alissa and
              Villalba-Mouco, Vanessa and Neumann, Gunnar U and Rivollat, Maïté
              and van de Loosdrecht, Marieke S and Majander, Kerttu and
              Tukhbatova, Rezeda I and Musralina, Lyazzat and Ghalichi, Ayshin
              and Penske, Sandra and Sabin, Susanna and Michel, Megan and
              Gretzinger, Joscha and Nelson, Elizabeth A and Ferraz, Tiago and
              Nägele, Kathrin and Parker, Cody and Keller, Marcel and Guevara,
              Evelyn K and Feldman, Michal and Eisenmann, Stefanie and
              Skourtanioti, Eirini and Giffin, Karen and Gnecchi-Ruscone, Guido
              Alberto and Friederich, Susanne and Schimmenti, Vittoria and
              Khartanovich, Valery and Karapetian, Marina K and Chaplygin,
              Mikhail S and Kufterin, Vladimir V and Khokhlov, Aleksandr A and
              Chizhevsky, Andrey A and Stashenkov, Dmitry A and Kochkina, Anna F
              and Tejedor-Rodríguez, Cristina and de Lagrán, Íñigo
              García-Martínez and Arcusa-Magallón, Héctor and Garrido-Pena,
              Rafael and Royo-Guillén, José Ignacio and Nováček, Jan and
              Rottier, Stéphane and Kacki, Sacha and Saintot, Sylvie and
              Kaverzneva, Elena and Belinskiy, Andrej B and Velemínský, Petr and
              Limburský, Petr and Kostka, Michal and Loe, Louise and Popescu,
              Elizabeth and Clarke, Rachel and Lyons, Alice and Mortimer,
              Richard and Sajantila, Antti and de Armas, Yadira Chinique and
              Hernandez Godoy, Silvia Teresita and Hernández-Zaragoza, Diana I
              and Pearson, Jessica and Binder, Didier and Lefranc, Philippe and
              Kantorovich, Anatoly R and Maslov, Vladimir E and Lai, Luca and
              Zoledziewska, Magdalena and Beckett, Jessica F and Langová,
              Michaela and Danielisová, Alžběta and Ingman, Tara and Atiénzar,
              Gabriel García and de Miguel Ibáñez, Maria Paz and Romero,
              Alejandro and Sperduti, Alessandra and Beckett, Sophie and Salter,
              Susannah J and Zilivinskaya, Emma D and Vasil'ev, Dmitry V and von
              Heyking, Kristin and Burger, Richard L and Salazar, Lucy C and
              Amkreutz, Luc and Navruzbekov, Masnav and Rosenstock, Eva and
              Alonso-Fernández, Carmen and Slavchev, Vladimir and Kalmykov,
              Alexey A and Atabiev, Biaslan Ch and Batieva, Elena and Calmet,
              Micaela Alvarez and Llamas, Bastien and Schultz, Michael and
              Krauß, Raiko and Jiménez-Echevarría, Javier and Francken, Michael
              and Shnaider, Svetlana and de Knijff, Peter and Altena, Eveline
              and Van de Vijver, Katrien and Fehren-Schmitz, Lars and Tung,
              Tiffiny A and Lösch, Sandra and Dobrovolskaya, Maria and Makarov,
              Nikolaj and Read, Chris and Van Twest, Melanie and Sagona, Claudia
              and Ramsl, Peter C and Akar, Murat and Yener, K Aslihan and
              Ballestero, Eduardo Carmona and Cucca, Francesco and Mazzarello,
              Vittorio and Utrilla, Pilar and Rademaker, Kurt and
              Fernández-Domínguez, Eva and Baird, Douglas and Semal, Patrick and
              Márquez-Morfín, Lourdes and Roksandic, Mirjana and Steiner, Hubert
              and Salazar-García, Domingo Carlos and Shishlina, Natalia and
              Erdal, Yilmaz Selim and Hallgren, Fredrik and Boyadzhiev, Yavor
              and Boyadzhiev, Kamen and Küßner, Mario and Sayer, Duncan and
              Onkamo, Päivi and Skeates, Robin and Rojo-Guerra, Manuel and
              Buzhilova, Alexandra and Khussainova, Elmira and Djansugurova,
              Leyla B and Beisenov, Arman Z and Samashev, Zainolla and Massy,
              Ken and Mannino, Marcello and Moiseyev, Vyacheslav and Mannermaa,
              Kristiina and Balanovsky, Oleg and Deguilloux, Marie-France and
              Reinhold, Sabine and Hansen, Svend and Kitov, Egor P and Dobeš,
              Miroslav and Ernée, Michal and Meller, Harald and Alt, Kurt W and
              Prüfer, Kay and Warinner, Christina and Schiffels, Stephan and
              Stockhammer, Philipp W and Bos, Kirsten and Posth, Cosimo and
              Herbig, Alexander and Haak, Wolfgang and Krause, Johannes and
              Kühnert, Denise",
  journal  = "Science",
  volume   =  374,
  number   =  6564,
  pages    = "182--188",
  abstract = "[Figure: see text].",
  month    =  oct,
  year     =  2021,
  url      = "http://dx.doi.org/10.1126/science.abi5658",
  doi      = "10.1126/science.abi5658",
  pmid     =  34618559,
  issn     = "0036-8075,1095-9203",
  language = "en"
}

@ARTICLE{Fellows_Yates2021-jl,
  title     = "Reproducible, portable, and efficient ancient genome
               reconstruction with nf-core/eager",
  author    = "Fellows Yates, James A and Lamnidis, Thiseas C and Borry, Maxime
               and Andrades Valtueña, Aida and Fagernäs, Zandra and Clayton,
               Stephen and Garcia, Maxime U and Neukamm, Judith and Peltzer,
               Alexander",
  journal   = "PeerJ",
  publisher = "PeerJ Inc.",
  volume    =  9,
  pages     = "e10947",
  abstract  = "The broadening utilisation of ancient DNA to address
               archaeological, palaeontological, and biological questions is
               resulting in a rising diversity in the size of laboratories and
               scale of analyses being performed. In the context of this
               heterogeneous landscape, we present an advanced, and entirely
               redesigned and extended version of the EAGER pipeline for the
               analysis of ancient genomic data. This Nextflow pipeline aims to
               address three main themes: accessibility and adaptability to
               different computing configurations, reproducibility to ensure
               robust analytical standards, and updating the pipeline to the
               latest routine ancient genomic practices. The new version of
               EAGER has been developed within the nf-core initiative to ensure
               high-quality software development and maintenance support;
               contributing to a long-term life-cycle for the pipeline.
               nf-core/eager will assist in ensuring that a wider range of
               ancient DNA analyses can be applied by a diverse range of
               research groups and fields.",
  month     =  mar,
  year      =  2021,
  url       = "http://dx.doi.org/10.7717/peerj.10947",
  keywords  = "Bioinformatics; Palaeogenomics; Ancient DNA; Pipeline; Nextflow;
               Reproducibility; Genomics; Metagenomics",
  doi       = "10.7717/peerj.10947",
  pmc       = "PMC7977378",
  pmid      =  33777521,
  issn      = "2167-8359",
  language  = "en"
}

@ARTICLE{Schubert2014-ps,
  title    = "Characterization of ancient and modern genomes by {SNP} detection
              and phylogenomic and metagenomic analysis using {PALEOMIX}",
  author   = "Schubert, Mikkel and Ermini, Luca and Der Sarkissian, Clio and
              Jónsson, Hákon and Ginolhac, Aurélien and Schaefer, Robert and
              Martin, Michael D and Fernández, Ruth and Kircher, Martin and
              McCue, Molly and Willerslev, Eske and Orlando, Ludovic",
  journal  = "Nature protocols",
  volume   =  9,
  number   =  5,
  pages    = "1056--1082",
  abstract = "Next-generation sequencing technologies have revolutionized the
              field of paleogenomics, allowing the reconstruction of complete
              ancient genomes and their comparison with modern references.
              However, this requires the processing of vast amounts of data and
              involves a large number of steps that use a variety of
              computational tools. Here we present PALEOMIX
              (http://geogenetics.ku.dk/publications/paleomix), a flexible and
              user-friendly pipeline applicable to both modern and ancient
              genomes, which largely automates the in silico analyses behind
              whole-genome resequencing. Starting with next-generation
              sequencing reads, PALEOMIX carries out adapter removal, mapping
              against reference genomes, PCR duplicate removal, characterization
              of and compensation for postmortem damage, SNP calling and
              maximum-likelihood phylogenomic inference, and it profiles the
              metagenomic contents of the samples. As such, PALEOMIX allows for
              a series of potential applications in paleogenomics, comparative
              genomics and metagenomics. Applying the PALEOMIX pipeline to the
              three ancient and seven modern Phytophthora infestans genomes as
              described here takes 5 d using a 16-core server.",
  month    =  may,
  year     =  2014,
  url      = "http://dx.doi.org/10.1038/nprot.2014.063",
  doi      = "10.1038/nprot.2014.063",
  pmid     =  24722405,
  issn     = "1754-2189,1750-2799"
}

@UNPUBLISHED{Pochon2022-hj,
  title    = "{aMeta}: an accurate and memory-efficient ancient Metagenomic
              profiling workflow",
  author   = "Pochon, Zoé and Bergfeldt, Nora and Kırdök, Emrah and Vicente,
              Mário and Naidoo, Thijessen and van der Valk, Tom and Ezgi
              Altınışık, N and Krzewińska, Maja and Dalen, Love and Götherström,
              Anders and Mirabello, Claudio and Unneberg, Per and Oskolkov,
              Nikolay",
  journal  = "bioRxiv",
  pages    = "2022.10.03.510579",
  abstract = "Analysis of microbial data from archaeological samples is a
              rapidly growing field with a great potential for understanding
              ancient environments, lifestyles and disease spread in the past.
              However, high error rates have been a long-standing challenge in
              ancient metagenomics analysis. This is also complicated by a
              limited choice of ancient microbiome specific computational
              frameworks that meet the growing computational demands of the
              field. Here, we propose aMeta, an accurate ancient Metagenomic
              profiling workflow designed primarily to minimize the amount of
              false discoveries and computer memory requirements. Using
              simulated ancient metagenomic samples, we benchmark aMeta against
              a current state-of-the-art workflow, and demonstrate its superior
              sensitivity and specificity in both microbial detection and
              authentication, as well as substantially lower usage of computer
              memory. aMeta is implemented as a Snakemake workflow to facilitate
              use and reproducibility. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  month    =  oct,
  year     =  2022,
  url      = "https://www.biorxiv.org/content/10.1101/2022.10.03.510579v1",
  doi      = "10.1101/2022.10.03.510579",
  language = "en"
}

@article{Almeida2021,
  title = {A Unified Catalog of 204,938 Reference Genomes from the Human Gut Microbiome},
  author = {Almeida, Alexandre and Nayfach, Stephen and Boland, Miguel and Strozzi, Francesco and Beracochea, Martin and Shi, Zhou Jason and Pollard, Katherine S. and Sakharova, Ekaterina and Parks, Donovan H. and Hugenholtz, Philip and Segata, Nicola and Kyrpides, Nikos C. and Finn, Robert D.},
  year = {2021},
  month = jan,
  journal = {Nature Biotechnology},
  volume = {39},
  number = {1},
  pages = {105--114},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/s41587-020-0603-3},
  urldate = {2022-09-01},
  abstract = {Comprehensive, high-quality reference genomes are required for functional characterization and taxonomic assignment of the human gut microbiota. We present the Unified Human Gastrointestinal Genome (UHGG) collection, comprising 204,938 nonredundant genomes from 4,644 gut prokaryotes. These genomes encode {$>$}170 million protein sequences, which we collated in the Unified Human Gastrointestinal Protein (UHGP) catalog. The UHGP more than doubles the number of gut proteins in comparison to those present in the Integrated Gene Catalog. More than 70\% of the UHGG species lack cultured representatives, and 40\% of the UHGP lack functional annotations. Intraspecies genomic variation analyses revealed a large reservoir of accessory genes and single-nucleotide variants, many of which are specific to individual human populations. The UHGG and UHGP collections will enable studies linking genotypes to phenotypes in the human gut microbiome.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Metagenomics,Microbiome},
  file = {/Users/huebner/Zotero/storage/HD6RVCZC/s41587-020-0603-3.html}
}

@article{Alneberg2014,
  title = {Binning Metagenomic Contigs by Coverage and Composition},
  author = {Alneberg, Johannes and Bjarnason, Brynjar Sm{\'a}ri and {de Bruijn}, Ino and Schirmer, Melanie and Quick, Joshua and Ijaz, Umer Z. and Lahti, Leo and Loman, Nicholas J. and Andersson, Anders F. and Quince, Christopher},
  year = {2014},
  month = nov,
  journal = {Nature Methods},
  volume = {11},
  number = {11},
  pages = {1144--1146},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/nmeth.3103},
  urldate = {2022-06-21},
  abstract = {The CONCOCT software performs unsupervised binning of metagenomic contigs across multiple samples to allow better genome reconstruction from microbial communities.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english}
}

@article{Borry2021,
  title = {{{PyDamage}}: Automated Ancient Damage Identification and Estimation for Contigs in Ancient {{DNA}} de Novo Assembly},
  shorttitle = {{{PyDamage}}},
  author = {Borry, Maxime and H{\"u}bner, Alexander and Rohrlach, Adam B. and Warinner, Christina},
  year = {2021},
  journal = {PeerJ},
  volume = {9},
  pages = {e11845},
  issn = {2167-8359},
  doi = {10.7717/peerj.11845},
  abstract = {DNA de novo assembly can be used to reconstruct longer stretches of DNA (contigs), including genes and even genomes, from short DNA sequencing reads. Applying this technique to metagenomic data derived from archaeological remains, such as paleofeces and dental calculus, we can investigate past microbiome functional diversity that may be absent or underrepresented in the modern microbiome gene catalogue. However, compared to modern samples, ancient samples are often burdened with environmental contamination, resulting in metagenomic datasets that represent mixtures of ancient and modern DNA. The ability to rapidly and reliably establish the authenticity and integrity of ancient samples is essential for ancient DNA studies, and the ability to distinguish between ancient and modern sequences is particularly important for ancient microbiome studies. Characteristic patterns of ancient DNA damage, namely DNA fragmentation and cytosine deamination (observed as C-to-T transitions) are typically used to authenticate ancient samples and sequences, but existing tools for inspecting and filtering aDNA damage either compute it at the read level, which leads to high data loss and lower quality when used in combination with de novo assembly, or require manual inspection, which is impractical for ancient assemblies that typically contain tens to hundreds of thousands of contigs. To address these challenges, we designed PyDamage, a robust, automated approach for aDNA damage estimation and authentication of de novo assembled aDNA. PyDamage uses a likelihood ratio based approach to discriminate between truly ancient contigs and contigs originating from modern contamination. We test PyDamage on both on simulated aDNA data and archaeological paleofeces, and we demonstrate its ability to reliably and automatically identify contigs bearing DNA damage characteristic of aDNA. Coupled with aDNA de novo assembly, Pydamage opens up new doors to explore functional diversity in ancient metagenomic datasets.},
  langid = {english},
  pmcid = {PMC8323603},
  pmid = {34395085},
  keywords = {aDNA,ancient DNA,assembly,automated,damage,de novo,metagenomics}
}

@article{Bowers2017,
  title = {Minimum Information about a Single Amplified Genome ({{MISAG}}) and a Metagenome-Assembled Genome ({{MIMAG}}) of Bacteria and Archaea},
  author = {Bowers, Robert M. and Kyrpides, Nikos C. and Stepanauskas, Ramunas and {Harmon-Smith}, Miranda and Doud, Devin and Reddy, T. B. K. and Schulz, Frederik and Jarett, Jessica and Rivers, Adam R. and {Eloe-Fadrosh}, Emiley A. and Tringe, Susannah G. and Ivanova, Natalia N. and Copeland, Alex and Clum, Alicia and Becraft, Eric D. and Malmstrom, Rex R. and Birren, Bruce and Podar, Mircea and Bork, Peer and Weinstock, George M. and Garrity, George M. and Dodsworth, Jeremy A. and Yooseph, Shibu and Sutton, Granger and Gl{\"o}ckner, Frank O. and Gilbert, Jack A. and Nelson, William C. and Hallam, Steven J. and Jungbluth, Sean P. and Ettema, Thijs J. G. and Tighe, Scott and Konstantinidis, Konstantinos T. and Liu, Wen-Tso and Baker, Brett J. and Rattei, Thomas and Eisen, Jonathan A. and Hedlund, Brian and McMahon, Katherine D. and Fierer, Noah and Knight, Rob and Finn, Rob and Cochrane, Guy and {Karsch-Mizrachi}, Ilene and Tyson, Gene W. and Rinke, Christian and Lapidus, Alla and Meyer, Folker and Yilmaz, Pelin and Parks, Donovan H. and Murat Eren, A. and Schriml, Lynn and Banfield, Jillian F. and Hugenholtz, Philip and Woyke, Tanja},
  year = {2017},
  month = aug,
  journal = {Nature Biotechnology},
  volume = {35},
  number = {8},
  pages = {725--731},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.3893},
  urldate = {2022-07-05},
  abstract = {Standards for sequencing the microbial 'uncultivated majority', namely bacterial and archaeal single-cell genome sequences, and genome sequences from metagenomic datasets, are proposed.},
  copyright = {2017 The Author(s)},
  langid = {english}
}

@article{Chaumeil2020,
  title = {{{GTDB-Tk}}: A Toolkit to Classify Genomes with the {{Genome Taxonomy Database}}},
  shorttitle = {{{GTDB-Tk}}},
  author = {Chaumeil, Pierre-Alain and Mussig, Aaron J and Hugenholtz, Philip and Parks, Donovan H},
  year = {2020},
  month = mar,
  journal = {Bioinformatics},
  volume = {36},
  number = {6},
  pages = {1925--1927},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btz848},
  urldate = {2022-07-13},
  abstract = {The Genome Taxonomy Database Toolkit (GTDB-Tk) provides objective taxonomic assignments for bacterial and archaeal genomes based on the GTDB. GTDB-Tk is computationally efficient and able to classify thousands of draft genomes in parallel. Here we demonstrate the accuracy of the GTDB-Tk taxonomic assignments by evaluating its performance on a phylogenetically diverse set of 10\,156 bacterial and archaeal metagenome-assembled genomes.GTDB-Tk is implemented in Python and licenced under the GNU General Public Licence v3.0. Source code and documentation are available at: https://github.com/ecogenomics/gtdbtk.Supplementary data are available at Bioinformatics online.}
}

@article{Chen2018,
  title = {Fastp: An Ultra-Fast All-in-One {{FASTQ}} Preprocessor},
  shorttitle = {Fastp},
  author = {Chen, Shifu and Zhou, Yanqing and Chen, Yaru and Gu, Jia},
  year = {2018},
  month = sep,
  journal = {Bioinformatics},
  volume = {34},
  number = {17},
  pages = {i884-i890},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bty560},
  urldate = {2022-05-03},
  abstract = {Quality control and preprocessing of FASTQ files are essential to providing clean data for downstream analysis. Traditionally, a different tool is used for each operation, such as quality control, adapter trimming and quality filtering. These tools are often insufficiently fast as most are developed using high-level programming languages (e.g. Python and Java) and provide limited multi-threading support. Reading and loading data multiple times also renders preprocessing slow and I/O inefficient.We developed fastp as an ultra-fast FASTQ preprocessor with useful quality control and data-filtering features. It can perform quality control, adapter trimming, quality filtering, per-read quality pruning and many other operations with a single scan of the FASTQ data. This tool is developed in C++ and has multi-threading support. Based on our evaluation, fastp is 2\textendash 5 times faster than other FASTQ preprocessing tools such as Trimmomatic or Cutadapt despite performing far more operations than similar tools.The open-source code and corresponding instructions are available at https://github.com/OpenGene/fastp.}
}

@misc{Chklovski2022,
  title = {{{CheckM2}}: A Rapid, Scalable and Accurate Tool for Assessing Microbial Genome Quality Using Machine Learning},
  shorttitle = {{{CheckM2}}},
  author = {Chklovski, Alex and Parks, Donovan H. and Woodcroft, Ben J. and Tyson, Gene W.},
  year = {2022},
  month = jul,
  primaryclass = {New Results},
  pages = {2022.07.11.499243},
  publisher = {{bioRxiv}},
  doi = {10.1101/2022.07.11.499243},
  urldate = {2023-07-26},
  abstract = {Advances in DNA sequencing and bioinformatics have dramatically increased the rate of recovery of microbial genomes from metagenomic data. Assessing the quality of metagenome-assembled genomes (MAGs) is a critical step prior to downstream analysis. Here, we present CheckM2, an improved method of predicting the completeness and contamination of MAGs using machine learning. We demonstrate the effectiveness of CheckM2 on synthetic and experimental data, and show that it outperforms the original version of CheckM in predicting MAG quality. CheckM2 is substantially faster than CheckM and its database can be rapidly updated with new high-quality reference genomes. We show that CheckM2 accurately predicts genome quality for MAGs from novel lineages, even those with sparse genomic representation, or reduced genome size (e.g. symbionts) such as those found in the Patescibacteria and the DPANN superphylum. CheckM2 provides accurate genome quality predictions across the microbial tree of life, giving increased confidence when inferring novel biological conclusions from MAGs.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {\textcopyright{} 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english}
}

@article{Jonsson2013,
  title = {{{mapDamage2}}.0: Fast Approximate {{Bayesian}} Estimates of Ancient {{DNA}} Damage Parameters},
  shorttitle = {{{mapDamage2}}.0},
  author = {J{\'o}nsson, H{\'a}kon and Ginolhac, Aur{\'e}lien and Schubert, Mikkel and Johnson, Philip L. F. and Orlando, Ludovic},
  year = {2013},
  month = jul,
  journal = {Bioinformatics},
  volume = {29},
  number = {13},
  pages = {1682--1684},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btt193},
  urldate = {2023-07-28},
  abstract = {Motivation: Ancient DNA (aDNA) molecules in fossilized bones and teeth, coprolites, sediments, mummified specimens and museum collections represent fantastic sources of information for evolutionary biologists, revealing the agents of past epidemics and the dynamics of past populations. However, the analysis of aDNA generally faces two major issues. Firstly, sequences consist of a mixture of endogenous and various exogenous backgrounds, mostly microbial. Secondly, high nucleotide misincorporation rates can be observed as a result of severe post-mortem DNA damage. Such misincorporation patterns are instrumental to authenticate ancient sequences versus modern contaminants. We recently developed the user-friendly mapDamage package that identifies such patterns from next-generation sequencing (NGS) sequence datasets. The absence of formal statistical modeling of the DNA damage process, however, precluded rigorous quantitative comparisons across samples.Results: Here, we describe mapDamage 2.0 that extends the original features of mapDamage by incorporating a statistical model of DNA damage. Assuming that damage events depend only on sequencing position and post-mortem deamination, our Bayesian statistical framework provides estimates of four key features of aDNA molecules: the average length of overhangs ({$\lambda$}), nick frequency ({$\nu$}) and cytosine deamination rates in both double-stranded regions () and overhangs (). Our model enables rescaling base quality scores according to their probability of being damaged. mapDamage 2.0 handles NGS datasets with ease and is compatible with a wide range of DNA library protocols.Availability: mapDamage 2.0 is available at ginolhac.github.io/mapDamage/ as a Python package and documentation is maintained at the Centre for GeoGenetics Web site (geogenetics.ku.dk/publications/mapdamage2.0/).Contact: ~jonsson.hakon@gmail.comSupplementary information: ~Supplementary data are available at Bioinformatics online.}
}

@article{Kang2019,
  title = {{{MetaBAT}} 2: An Adaptive Binning Algorithm for Robust and Efficient Genome Reconstruction from Metagenome Assemblies},
  shorttitle = {{{MetaBAT}} 2},
  author = {Kang, Dongwan D. and Li, Feng and Kirton, Edward and Thomas, Ashleigh and Egan, Rob and An, Hong and Wang, Zhong},
  year = {2019},
  month = jul,
  journal = {PeerJ},
  volume = {7},
  pages = {e7359},
  publisher = {{PeerJ Inc.}},
  issn = {2167-8359},
  doi = {10.7717/peerj.7359},
  urldate = {2022-06-21},
  abstract = {We previously reported on MetaBAT, an automated metagenome binning software tool to reconstruct single genomes from microbial communities for subsequent analyses of uncultivated microbial species. MetaBAT has become one of the most popular binning tools largely due to its computational efficiency and ease of use, especially in binning experiments with a large number of samples and a large assembly. MetaBAT requires users to choose parameters to fine-tune its sensitivity and specificity. If those parameters are not chosen properly, binning accuracy can suffer, especially on assemblies of poor quality. Here, we developed MetaBAT 2 to overcome this problem. MetaBAT 2 uses a new adaptive binning algorithm to eliminate manual parameter tuning. We also performed extensive software engineering optimization to increase both computational and memory efficiency. Comparing MetaBAT 2 to alternative software tools on over 100 real world metagenome assemblies shows superior accuracy and computing speed. Binning a typical metagenome assembly takes only a few minutes on a single commodity workstation. We therefore recommend the community adopts MetaBAT 2 for their metagenome binning experiments. MetaBAT 2 is open source software and available at https://bitbucket.org/berkeleylab/metabat.},
  langid = {english}
}

@article{Klapper2023,
  title = {Natural Products from Reconstructed Bacterial Genomes of the {{Middle}} and {{Upper Paleolithic}}},
  author = {Klapper, Martin and H{\"u}bner, Alexander and Ibrahim, Anan and Wasmuth, Ina and Borry, Maxime and Haensch, Veit G. and Zhang, Shuaibing and {Al-Jammal}, Walid K. and Suma, Harikumar and Fellows Yates, James A. and Frangenberg, Jasmin and Velsko, Irina M. and Chowdhury, Somak and Herbst, Rosa and Bratovanov, Evgeni V. and Dahse, Hans-Martin and Horch, Therese and Hertweck, Christian and Gonz{\'a}lez Morales, Manuel Ramon and Straus, Lawrence Guy and Vilotijevic, Ivan and Warinner, Christina and Stallforth, Pierre},
  year = {2023},
  month = may,
  journal = {Science},
  volume = {380},
  number = {6645},
  pages = {619--624},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.adf5300},
  urldate = {2023-07-20},
  abstract = {Major advances over the past decade in the field of ancient DNA are providing access to past paleogenomic diversity, but the diverse functions and biosynthetic capabilities of this growing paleome remain largely elusive. We investigated the dental calculus of 12 Neanderthals and 52 anatomically modern humans ranging from 100,000 years ago to the present and reconstructed 459 bacterial metagenome-assembled genomes. We identified a biosynthetic gene cluster shared by seven Middle and Upper Paleolithic individuals that allows for the heterologous production of a class of previously unknown metabolites that we name ``paleofurans.'' This paleobiotechnological approach demonstrates that viable biosynthetic machinery can be produced from the preserved genetic material of ancient organisms, allowing access to natural products from the Pleistocene and providing a promising area for natural product exploration.}
}

@article{Krakau2022,
  title = {Nf-Core/Mag: A Best-Practice Pipeline for Metagenome Hybrid Assembly and Binning},
  shorttitle = {Nf-Core/Mag},
  author = {Krakau, Sabrina and Straub, Daniel and Gourl{\'e}, Hadrien and Gabernet, Gisela and Nahnsen, Sven},
  year = {2022},
  month = mar,
  journal = {NAR Genomics and Bioinformatics},
  volume = {4},
  number = {1},
  pages = {lqac007},
  issn = {2631-9268},
  doi = {10.1093/nargab/lqac007},
  urldate = {2023-07-20},
  abstract = {The analysis of shotgun metagenomic data provides valuable insights into microbial communities, while allowing resolution at individual genome level. In absence of complete reference genomes, this requires the reconstruction of metagenome assembled genomes (MAGs) from sequencing reads. We present the nf-core/mag pipeline for metagenome assembly, binning and taxonomic classification. It can optionally combine short and long reads to increase assembly continuity and utilize sample-wise group-information for co-assembly and genome binning. The pipeline is easy to install-all dependencies are provided within containers-portable and reproducible. It is written in Nextflow and developed as part of the nf-core initiative for best-practice pipeline development. All codes are hosted on GitHub under the nf-core organization https://github.com/nf-core/mag and released under the MIT license.}
}

@article{Leggett2013,
  title = {Identifying and {{Classifying Trait Linked Polymorphisms}} in {{Non-Reference Species}} by {{Walking Coloured}} de {{Bruijn Graphs}}},
  author = {Leggett, Richard M. and {Ramirez-Gonzalez}, Ricardo H. and Verweij, Walter and Kawashima, Cintia G. and Iqbal, Zamin and Jones, Jonathan D. G. and Caccamo, Mario and MacLean, Daniel},
  year = {2013},
  month = mar,
  journal = {PLOS ONE},
  volume = {8},
  number = {3},
  pages = {e60058},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0060058},
  urldate = {2023-07-20},
  abstract = {Single Nucleotide Polymorphisms are invaluable markers for tracing the genetic basis of inheritable traits and the ability to create marker libraries quickly is vital for timely identification of target genes. Next-generation sequencing makes it possible to sample a genome rapidly, but polymorphism detection relies on having a reference genome to which reads can be aligned and variants detected. We present Bubbleparse, a method for detecting variants directly from next-generation reads without a reference sequence. Bubbleparse uses the de Bruijn graph implementation in the Cortex framework as a basis and allows the user to identify bubbles in these graphs that represent polymorphisms, quickly, easily and sensitively. We show that the Bubbleparse algorithm is sensitive and can detect many polymorphisms quickly and that it performs well when compared with polymorphism detection methods based on alignment to a reference in Arabidopsis thaliana. We show that the heuristic can be used to maximise the number of true polymorphisms returned, and with a proof-of-principle experiment show that Bubbleparse is very effective on data from unsequenced wild relatives of potato and enabled us to identify disease resistance linked genes quickly and easily.},
  langid = {english}
}

@article{LiMegahit2015,
  title = {{{MEGAHIT}}: An Ultra-Fast Single-Node Solution for Large and Complex Metagenomics Assembly via Succinct de {{Bruijn}} Graph},
  shorttitle = {{{MEGAHIT}}},
  author = {Li, Dinghua and Liu, Chi-Man and Luo, Ruibang and Sadakane, Kunihiko and Lam, Tak-Wah},
  year = {2015},
  month = may,
  journal = {Bioinformatics},
  volume = {31},
  number = {10},
  pages = {1674--1676},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btv033},
  urldate = {2022-04-07},
  abstract = {Summary: MEGAHIT is a NGS de novo assembler for assembling large and complex metagenomics data in a time- and cost-efficient manner. It finished assembling a soil metagenomics dataset with 252\,Gbps in 44.1 and 99.6\,h on a single computing node with and without a graphics processing unit, respectively. MEGAHIT assembles the data as a whole, i.e. no pre-processing like partitioning and normalization was needed. When compared with previous methods on assembling the soil data, MEGAHIT generated a three-time larger assembly, with longer contig N50 and average contig length; furthermore, 55.8\% of the reads were aligned to the assembly, giving a fourfold improvement.Availability and implementation: The source code of MEGAHIT is freely available at https://github.com/voutcn/megahit under GPLv3 license.Contact:rb@l3-bioinfo.com or twlam@cs.hku.hkSupplementary information: Supplementary data are available at Bioinformatics online.}
}

@article{Maixner2021,
  title = {Hallstatt Miners Consumed Blue Cheese and Beer during the {{Iron Age}} and Retained a Non-{{Westernized}} Gut Microbiome until the {{Baroque}} Period},
  author = {Maixner, Frank and Sarhan, Mohamed S. and Huang, Kun D. and Tett, Adrian and Schoenafinger, Alexander and Zingale, Stefania and {Blanco-M{\'i}guez}, Aitor and Manghi, Paolo and {Cemper-Kiesslich}, Jan and Rosendahl, Wilfried and Kusebauch, Ulrike and Morrone, Seamus R. and Hoopmann, Michael R. and {Rota-Stabelli}, Omar and Rattei, Thomas and Moritz, Robert L. and Oeggl, Klaus and Segata, Nicola and Zink, Albert and Reschreiter, Hans and Kowarik, Kerstin},
  year = {2021},
  month = dec,
  journal = {Current Biology},
  volume = {31},
  number = {23},
  pages = {5149-5162.e6},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2021.09.031},
  urldate = {2023-07-05},
  abstract = {We subjected human paleofeces dating from the Bronze Age to the Baroque period (18th century AD) to in-depth microscopic, metagenomic, and proteomic analyses. The paleofeces were preserved in the underground salt mines of the UNESCO World Heritage site of Hallstatt in Austria. This allowed us to reconstruct the diet of the former population and gain insights into their ancient gut microbiome composition. Our dietary survey identified bran and glumes of different cereals as some of the most prevalent plant fragments. This highly fibrous, carbohydrate-rich diet was supplemented with proteins from broad beans and occasionally with fruits, nuts, or animal food products. Due to these traditional dietary habits, all ancient miners up to the Baroque period have gut microbiome structures akin to modern non-Westernized individuals whose diets are also mainly composed of unprocessed foods and fresh fruits and vegetables. This may indicate a shift in the gut community composition of modern Westernized populations due to quite recent dietary and lifestyle changes. When we extended our microbial survey to fungi present in the paleofeces, in one of the Iron Age samples, we observed a high abundance of Penicillium roqueforti and Saccharomyces cerevisiae DNA. Genome-wide analysis indicates that both fungi were involved in food fermentation and provides the first molecular evidence for blue cheese and beer consumption in Iron Age Europe. Video abstract},
  langid = {english}
}

@article{Manni2021,
  title = {{{BUSCO Update}}: {{Novel}} and {{Streamlined Workflows}} along with {{Broader}} and {{Deeper Phylogenetic Coverage}} for {{Scoring}} of {{Eukaryotic}}, {{Prokaryotic}}, and {{Viral Genomes}}},
  shorttitle = {{{BUSCO Update}}},
  author = {Manni, Mos{\`e} and Berkeley, Matthew R and Seppey, Mathieu and Sim{\~a}o, Felipe A and Zdobnov, Evgeny M},
  year = {2021},
  month = oct,
  journal = {Molecular Biology and Evolution},
  volume = {38},
  number = {10},
  pages = {4647--4654},
  issn = {1537-1719},
  doi = {10.1093/molbev/msab199},
  urldate = {2022-06-29},
  abstract = {Methods for evaluating the quality of genomic and metagenomic data are essential to aid genome assembly procedures and to correctly interpret the results of subsequent analyses. BUSCO estimates the completeness and redundancy of processed genomic data based on universal single-copy orthologs. Here, we present new functionalities and major improvements of the BUSCO software, as well as the renewal and expansion of the underlying data sets in sync with the OrthoDB v10 release. Among the major novelties, BUSCO now enables phylogenetic placement of the input sequence to automatically select the most appropriate BUSCO data set for the assessment, allowing the analysis of metagenome-assembled genomes of unknown origin. A newly introduced genome workflow increases the efficiency and runtimes especially on large eukaryotic genomes. BUSCO is the only tool capable of assessing both eukaryotic and prokaryotic species, and can be applied to various data types, from genome assemblies and metagenomic bins, to transcriptomes and gene sets.}
}

@article{Meyer2022,
  title = {Critical {{Assessment}} of {{Metagenome Interpretation}}: The Second Round of Challenges},
  shorttitle = {Critical {{Assessment}} of {{Metagenome Interpretation}}},
  author = {Meyer, Fernando and Fritz, Adrian and Deng, Zhi-Luo and Koslicki, David and Lesker, Till Robin and Gurevich, Alexey and Robertson, Gary and Alser, Mohammed and Antipov, Dmitry and Beghini, Francesco and Bertrand, Denis and Brito, Jaqueline J. and Brown, C. Titus and Buchmann, Jan and Bulu{\c c}, Aydin and Chen, Bo and Chikhi, Rayan and Clausen, Philip T. L. C. and Cristian, Alexandru and Dabrowski, Piotr Wojciech and Darling, Aaron E. and Egan, Rob and Eskin, Eleazar and Georganas, Evangelos and Goltsman, Eugene and Gray, Melissa A. and Hansen, Lars Hestbjerg and Hofmeyr, Steven and Huang, Pingqin and Irber, Luiz and Jia, Huijue and J{\o}rgensen, Tue Sparholt and Kieser, Silas D. and Klemetsen, Terje and Kola, Axel and Kolmogorov, Mikhail and Korobeynikov, Anton and Kwan, Jason and LaPierre, Nathan and Lemaitre, Claire and Li, Chenhao and Limasset, Antoine and {Malcher-Miranda}, Fabio and Mangul, Serghei and Marcelino, Vanessa R. and Marchet, Camille and Marijon, Pierre and Meleshko, Dmitry and Mende, Daniel R. and Milanese, Alessio and Nagarajan, Niranjan and Nissen, Jakob and Nurk, Sergey and Oliker, Leonid and Paoli, Lucas and Peterlongo, Pierre and Piro, Vitor C. and Porter, Jacob S. and Rasmussen, Simon and Rees, Evan R. and Reinert, Knut and Renard, Bernhard and Robertsen, Espen Mikal and Rosen, Gail L. and Ruscheweyh, Hans-Joachim and Sarwal, Varuni and Segata, Nicola and Seiler, Enrico and Shi, Lizhen and Sun, Fengzhu and Sunagawa, Shinichi and S{\o}rensen, S{\o}ren Johannes and Thomas, Ashleigh and Tong, Chengxuan and Trajkovski, Mirko and Tremblay, Julien and Uritskiy, Gherman and Vicedomini, Riccardo and Wang, Zhengyang and Wang, Ziye and Wang, Zhong and Warren, Andrew and Willassen, Nils Peder and Yelick, Katherine and You, Ronghui and Zeller, Georg and Zhao, Zhengqiao and Zhu, Shanfeng and Zhu, Jie and {Garrido-Oter}, Ruben and Gastmeier, Petra and Hacquard, Stephane and H{\"a}u{\ss}ler, Susanne and Khaledi, Ariane and Maechler, Friederike and Mesny, Fantin and Radutoiu, Simona and {Schulze-Lefert}, Paul and Smit, Nathiana and Strowig, Till and Bremges, Andreas and Sczyrba, Alexander and McHardy, Alice Carolyn},
  year = {2022},
  month = apr,
  journal = {Nature Methods},
  volume = {19},
  number = {4},
  pages = {429--440},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/s41592-022-01431-4},
  urldate = {2022-04-26},
  abstract = {Evaluating metagenomic software is key for optimizing metagenome interpretation and focus of the Initiative for the Critical Assessment of Metagenome Interpretation (CAMI). The CAMI II challenge engaged the community to assess methods on realistic and complex datasets with long- and short-read sequences, created computationally from around 1,700 new and known genomes, as well as 600 new plasmids and viruses. Here we analyze 5,002 results by 76 program versions. Substantial improvements were seen in assembly, some due to long-read data. Related strains still were challenging for assembly and genome recovery through binning, as was assembly quality for the latter. Profilers markedly matured, with taxon profilers and binners excelling at higher bacterial ranks, but underperforming for viruses and Archaea. Clinical pathogen detection results revealed a need to improve reproducibility. Runtime and memory usage analyses identified efficient programs, including top performers with other metrics. The results identify challenges and guide researchers in selecting methods for analyses.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Classification and taxonomy,Metagenomics,Software}
}

@article{Mirdita2021,
  title = {Fast and Sensitive Taxonomic Assignment to Metagenomic Contigs},
  author = {Mirdita, M and Steinegger, M and Breitwieser, F and S{\"o}ding, J and Levy Karin, E},
  year = {2021},
  month = sep,
  journal = {Bioinformatics},
  volume = {37},
  number = {18},
  pages = {3029--3031},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btab184},
  urldate = {2022-07-05},
  abstract = {MMseqs2 taxonomy is a new tool to assign taxonomic labels to metagenomic contigs. It extracts all possible protein fragments from each contig, quickly retains those that can contribute to taxonomic annotation, assigns them with robust labels and determines the contig's taxonomic identity by weighted voting. Its fragment extraction step is suitable for the analysis of all domains of life. MMseqs2 taxonomy is 2\textendash 18\texttimes{} faster than state-of-the-art tools and also contains new modules for creating and manipulating taxonomic reference databases as well as reporting and visualizing taxonomic assignments.MMseqs2 taxonomy is part of the MMseqs2 free open-source software package available for Linux, macOS and Windows at https://mmseqs.com.Supplementary data are available at Bioinformatics online.}
}

@article{Neukamm2021,
  title = {{{DamageProfiler}}: Fast Damage Pattern Calculation for Ancient {{DNA}}},
  shorttitle = {{{DamageProfiler}}},
  author = {Neukamm, Judith and Peltzer, Alexander and Nieselt, Kay},
  year = {2021},
  month = oct,
  journal = {Bioinformatics},
  volume = {37},
  number = {20},
  pages = {3652--3653},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btab190},
  urldate = {2022-07-14},
  abstract = {In ancient DNA research, the authentication of ancient samples based on specific features remains a crucial step in data analysis. Because of this central importance, researchers lacking deeper programming knowledge should be able to run a basic damage authentication analysis. Such software should be user-friendly and easy to integrate into an analysis pipeline.DamageProfiler is a Java-based, stand-alone software to determine damage patterns in ancient DNA. The results are provided in various file formats and plots for further processing. DamageProfiler has an intuitive graphical as well as command line interface that allows the tool to be easily embedded into an analysis pipeline.All of the source code is freely available on GitHub (https://github.com/Integrative-Transcriptomics/DamageProfiler).Supplementary data are available at Bioinformatics online.}
}

@article{Nurk2017,
  title = {{{metaSPAdes}}: A New Versatile Metagenomic Assembler},
  shorttitle = {{{metaSPAdes}}},
  author = {Nurk, Sergey and Meleshko, Dmitry and Korobeynikov, Anton and Pevzner, Pavel A.},
  year = {2017},
  month = may,
  journal = {Genome Research},
  volume = {27},
  number = {5},
  pages = {824--834},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.213959.116},
  urldate = {2022-06-13},
  abstract = {While metagenomics has emerged as a technology of choice for analyzing bacterial populations, the assembly of metagenomic data remains challenging, thus stifling biological discoveries. Moreover, recent studies revealed that complex bacterial populations may be composed from dozens of related strains, thus further amplifying the challenge of metagenomic assembly. metaSPAdes addresses various challenges of metagenomic assembly by capitalizing on computational ideas that proved to be useful in assemblies of single cells and highly polymorphic diploid genomes. We benchmark metaSPAdes against other state-of-the-art metagenome assemblers and demonstrate that it results in high-quality assemblies across diverse data sets.},
  langid = {english},
  pmid = {28298430}
}

@article{Orakov2021,
  title = {{{GUNC}}: Detection of Chimerism and Contamination in Prokaryotic Genomes},
  shorttitle = {{{GUNC}}},
  author = {Orakov, Askarbek and Fullam, Anthony and Coelho, Luis Pedro and Khedkar, Supriya and Szklarczyk, Damian and Mende, Daniel R. and Schmidt, Thomas S. B. and Bork, Peer},
  year = {2021},
  month = jun,
  journal = {Genome Biology},
  volume = {22},
  number = {1},
  pages = {178},
  issn = {1474-760X},
  doi = {10.1186/s13059-021-02393-0},
  urldate = {2022-06-21},
  abstract = {Genomes are critical units in microbiology, yet ascertaining quality in prokaryotic genome assemblies remains a formidable challenge. We present GUNC (the Genome UNClutterer), a tool that accurately detects and quantifies genome chimerism based on the lineage homogeneity of individual contigs using a genome's full complement of genes. GUNC complements existing approaches by targeting previously underdetected types of contamination: we conservatively estimate that 5.7\% of genomes in GenBank, 5.2\% in RefSeq, and 15\textendash 30\% of pre-filtered ``high-quality'' metagenome-assembled genomes in recent studies are undetected chimeras. GUNC provides a fast and robust tool to substantially improve prokaryotic genome quality.},
  langid = {english}
}

@article{Orlando2013,
  title = {Recalibrating {{Equus}} Evolution Using the Genome Sequence of an Early {{Middle Pleistocene}} Horse},
  author = {Orlando, Ludovic and Ginolhac, Aur{\'e}lien and Zhang, Guojie and Froese, Duane and Albrechtsen, Anders and Stiller, Mathias and Schubert, Mikkel and Cappellini, Enrico and Petersen, Bent and Moltke, Ida and Johnson, Philip L. F. and Fumagalli, Matteo and Vilstrup, Julia T. and Raghavan, Maanasa and Korneliussen, Thorfinn and Malaspinas, Anna-Sapfo and Vogt, Josef and Szklarczyk, Damian and Kelstrup, Christian D. and Vinther, Jakob and Dolocan, Andrei and Stenderup, Jesper and Velazquez, Amhed M. V. and Cahill, James and Rasmussen, Morten and Wang, Xiaoli and Min, Jiumeng and Zazula, Grant D. and {Seguin-Orlando}, Andaine and Mortensen, Cecilie and Magnussen, Kim and Thompson, John F. and Weinstock, Jacobo and Gregersen, Kristian and R{\o}ed, Knut H. and Eisenmann, V{\'e}ra and Rubin, Carl J. and Miller, Donald C. and Antczak, Douglas F. and Bertelsen, Mads F. and Brunak, S{\o}ren and {Al-Rasheid}, Khaled A. S. and Ryder, Oliver and Andersson, Leif and Mundy, John and Krogh, Anders and Gilbert, M. Thomas P. and Kj{\ae}r, Kurt and {Sicheritz-Ponten}, Thomas and Jensen, Lars Juhl and Olsen, Jesper V. and Hofreiter, Michael and Nielsen, Rasmus and Shapiro, Beth and Wang, Jun and Willerslev, Eske},
  year = {2013},
  month = jul,
  journal = {Nature},
  volume = {499},
  number = {7456},
  pages = {74--78},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature12323},
  urldate = {2023-07-05},
  abstract = {A low-coverage draft genome sequence from a horse bone recovered from permafrost dated to approximately 560\textendash 780 thousand years ago is presented; this represents the oldest full genome sequence to date by almost an order of magnitude.},
  copyright = {2013 Springer Nature Limited},
  langid = {english}
}

@article{Parks2015,
  title = {{{CheckM}}: Assessing the Quality of Microbial Genomes Recovered from Isolates, Single Cells, and Metagenomes},
  shorttitle = {{{CheckM}}},
  author = {Parks, Donovan H. and Imelfort, Michael and Skennerton, Connor T. and Hugenholtz, Philip and Tyson, Gene W.},
  year = {2015},
  month = jul,
  journal = {Genome Research},
  volume = {25},
  number = {7},
  pages = {1043--1055},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.186072.114},
  urldate = {2022-06-21},
  abstract = {Large-scale recovery of genomes from isolates, single cells, and metagenomic data has been made possible by advances in computational methods and substantial reductions in sequencing costs. Although this increasing breadth of draft genomes is providing key information regarding the evolutionary and functional diversity of microbial life, it has become impractical to finish all available reference genomes. Making robust biological inferences from draft genomes requires accurate estimates of their completeness and contamination. Current methods for assessing genome quality are ad hoc and generally make use of a limited number of ``marker'' genes conserved across all bacterial or archaeal genomes. Here we introduce CheckM, an automated method for assessing the quality of a genome using a broader set of marker genes specific to the position of a genome within a reference genome tree and information about the collocation of these genes. We demonstrate the effectiveness of CheckM using synthetic data and a wide range of isolate-, single-cell-, and metagenome-derived genomes. CheckM is shown to provide accurate estimates of genome completeness and contamination and to outperform existing approaches. Using CheckM, we identify a diverse range of errors currently impacting publicly available isolate genomes and demonstrate that genomes obtained from single cells and metagenomic data vary substantially in quality. In order to facilitate the use of draft genomes, we propose an objective measure of genome quality that can be used to select genomes suitable for specific gene- and genome-centric analyses of microbial communities.},
  langid = {english},
  pmid = {25977477}
}

@article{Parks2020,
  title = {A Complete Domain-to-Species Taxonomy for {{Bacteria}} and {{Archaea}}},
  author = {Parks, Donovan H. and Chuvochina, Maria and Chaumeil, Pierre-Alain and Rinke, Christian and Mussig, Aaron J. and Hugenholtz, Philip},
  year = {2020},
  month = sep,
  journal = {Nature Biotechnology},
  volume = {38},
  number = {9},
  pages = {1079--1086},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/s41587-020-0501-8},
  urldate = {2022-07-05},
  abstract = {The Genome Taxonomy Database is a phylogenetically consistent, genome-based taxonomy that provides rank-normalized classifications for \textasciitilde 150,000 bacterial and archaeal genomes from domain to genus. However, almost 40\% of the genomes in the Genome Taxonomy Database lack a species name. We address this limitation by using commonly accepted average nucleotide identity criteria to set bounds on species and propose species clusters that encompass all publicly available bacterial and archaeal genomes. Unlike previous average nucleotide identity studies, we chose a single representative genome to serve as the effective nomenclatural `type' defining each species. Of the 24,706 proposed species clusters, 8,792 are based on published names. We assigned placeholder names to the remaining 15,914 species clusters to provide names to the growing number of genomes from uncultivated species. This resource provides a complete domain-to-species taxonomic framework for bacterial and archaeal genomes, which will facilitate research on uncultivated species and improve communication of scientific results.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english}
}

@article{Schwengers2021,
  title = {Bakta: Rapid and Standardized Annotation of Bacterial Genomes via Alignment-Free Sequence Identification},
  shorttitle = {Bakta},
  author = {Schwengers, Oliver and Jelonek, Lukas and Dieckmann, Marius Alfred and Beyvers, Sebastian and Blom, Jochen and Goesmann, AlexanderYR 2021},
  year = {2021},
  journal = {Microbial Genomics},
  volume = {7},
  number = {11},
  pages = {000685},
  publisher = {{Microbiology Society,}},
  issn = {2057-5858,},
  doi = {10.1099/mgen.0.000685},
  urldate = {2022-11-22},
  abstract = {Command-line annotation software tools have continuously gained popularity compared to centralized online services due to the worldwide increase of sequenced bacterial genomes. However, results of existing command-line software pipelines heavily depend on taxon-specific databases or sufficiently well annotated reference genomes. Here, we introduce Bakta, a new command-line software tool for the robust, taxon-independent, thorough and, nonetheless, fast annotation of bacterial genomes. Bakta conducts a comprehensive annotation workflow including the detection of small proteins taking into account replicon metadata. The annotation of coding sequences is accelerated via an alignment-free sequence identification approach that in addition facilitates the precise assignment of public database cross-references. Annotation results are exported in GFF3 and International Nucleotide Sequence Database Collaboration (INSDC)-compliant flat files, as well as comprehensive JSON files, facilitating automated downstream analysis. We compared Bakta to other rapid contemporary command-line annotation software tools in both targeted and taxonomically broad benchmarks including isolates and metagenomic-assembled genomes. We demonstrated that Bakta outperforms other tools in terms of functional annotations, the assignment of functional categories and database cross-references, whilst providing comparable wall-clock runtimes. Bakta is implemented in Python 3 and runs on MacOS and Linux systems. It is freely available under a GPLv3 license at https://github.com/oschwengers/bakta. An accompanying web version is available at https://bakta.computational.bio.,}
}

@article{Seemann2014,
  title = {Prokka: Rapid Prokaryotic Genome Annotation},
  shorttitle = {Prokka},
  author = {Seemann, Torsten},
  year = {2014},
  month = jul,
  journal = {Bioinformatics},
  volume = {30},
  number = {14},
  pages = {2068--2069},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btu153},
  urldate = {2022-04-12},
  abstract = {Summary: The multiplex capability and high yield of current day DNA-sequencing instruments has made bacterial whole genome sequencing a routine affair. The subsequent de novo assembly of reads into contigs has been well addressed. The final step of annotating all relevant genomic features on those contigs can be achieved slowly using existing web- and email-based systems, but these are not applicable for sensitive data or integrating into computational pipelines. Here we introduce Prokka, a command line software tool to fully annotate a draft bacterial genome in about 10 min on a typical desktop computer. It produces standards-compliant output files for further analysis or viewing in genome browsers. Availability and implementation: Prokka is implemented in Perl and is freely available under an open source GPLv2 license from http://vicbioinformatics.com/ . Contact:torsten.seemann@monash.edu}
}

@article{Steinegger2017,
  title = {{{MMseqs2}} Enables Sensitive Protein Sequence Searching for the Analysis of Massive Data Sets},
  author = {Steinegger, Martin and S{\"o}ding, Johannes},
  year = {2017},
  month = nov,
  journal = {Nature Biotechnology},
  volume = {35},
  number = {11},
  pages = {1026--1028},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.3988},
  urldate = {2022-07-04},
  copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english}
}

@article{Uritskiy2018,
  title = {{{MetaWRAP}}\textemdash a Flexible Pipeline for Genome-Resolved Metagenomic Data Analysis},
  author = {Uritskiy, Gherman V. and DiRuggiero, Jocelyne and Taylor, James},
  year = {2018},
  month = sep,
  journal = {Microbiome},
  volume = {6},
  number = {1},
  pages = {158},
  issn = {2049-2618},
  doi = {10.1186/s40168-018-0541-1},
  urldate = {2022-06-21},
  abstract = {The study of microbiomes using whole-metagenome shotgun sequencing enables the analysis of uncultivated microbial populations that may have important roles in their environments. Extracting individual draft genomes (bins) facilitates metagenomic analysis at the single genome level. Software and pipelines for such analysis have become diverse and sophisticated, resulting in a significant burden for biologists to access and use them. Furthermore, while bin extraction algorithms are rapidly improving, there is still a lack of tools for their evaluation and visualization.}
}

@article{Uritskiy2018,
  title = {{{MetaWRAP}}\textemdash a Flexible Pipeline for Genome-Resolved Metagenomic Data Analysis},
  author = {Uritskiy, Gherman V. and DiRuggiero, Jocelyne and Taylor, James},
  year = {2018},
  month = sep,
  journal = {Microbiome},
  volume = {6},
  number = {1},
  pages = {158},
  issn = {2049-2618},
  doi = {10.1186/s40168-018-0541-1},
  urldate = {2022-06-21},
  abstract = {The study of microbiomes using whole-metagenome shotgun sequencing enables the analysis of uncultivated microbial populations that may have important roles in their environments. Extracting individual draft genomes (bins) facilitates metagenomic analysis at the single genome level. Software and pipelines for such analysis have become diverse and sophisticated, resulting in a significant burden for biologists to access and use them. Furthermore, while bin extraction algorithms are rapidly improving, there is still a lack of tools for their evaluation and visualization.}
}

@article{Wright2023,
  title = {From Defaults to Databases: Parameter and Database Choice Dramatically Impact the Performance of Metagenomic Taxonomic Classification Tools},
  shorttitle = {From Defaults to Databases},
  author = {Wright, Robyn J. and Comeau, Andr{\`e} M. and Langille, Morgan G. I.},
  year = {2023},
  journal = {Microbial Genomics},
  volume = {9},
  number = {3},
  pages = {000949},
  publisher = {{Microbiology Society,}},
  issn = {2057-5858},
  doi = {10.1099/mgen.0.000949},
  urldate = {2023-07-27},
  abstract = {In metagenomic analyses of microbiomes, one of the first steps is usually the taxonomic classification of reads by comparison to a database of previously taxonomically classified genomes. While different studies comparing metagenomic taxonomic classification methods have determined that different tools are `best', there are two tools that have been used the most to-date: Kraken (k-mer-based classification against a user-constructed database) and MetaPhlAn (classification by alignment to clade-specific marker genes), the latest versions of which are Kraken2 and MetaPhlAn 3, respectively. We found large discrepancies in both the proportion of reads that were classified as well as the number of species that were identified when we used both Kraken2 and MetaPhlAn 3 to classify reads within metagenomes from human-associated or environmental datasets. We then investigated which of these tools would give classifications closest to the real composition of metagenomic samples using a range of simulated and mock samples and examined the combined impact of tool\textendash parameter\textendash database choice on the taxonomic classifications given. This revealed that there may not be a one-size-fits-all `best' choice. While Kraken2 can achieve better overall performance, with higher precision, recall and F1 scores, as well as alpha- and beta-diversity measures closer to the known composition than MetaPhlAn 3, the computational resources required for this may be prohibitive for many researchers, and the default database and parameters should not be used. We therefore conclude that the best tool\textendash parameter\textendash database choice for a particular application depends on the scientific question of interest, which performance metric is most important for this question and the limit of available computational resources.}
}

@article{WuMaxbin2016,
  title = {{{MaxBin}} 2.0: An Automated Binning Algorithm to Recover Genomes from Multiple Metagenomic Datasets},
  shorttitle = {{{MaxBin}} 2.0},
  author = {Wu, Yu-Wei and Simmons, Blake A. and Singer, Steven W.},
  year = {2016},
  month = feb,
  journal = {Bioinformatics},
  volume = {32},
  number = {4},
  pages = {605--607},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btv638},
  urldate = {2022-06-21},
  abstract = {Summary: The recovery of genomes from metagenomic datasets is a critical step to defining the functional roles of the underlying uncultivated populations. We previously developed MaxBin, an automated binning approach for high-throughput recovery of microbial genomes from metagenomes. Here we present an expanded binning algorithm, MaxBin 2.0, which recovers genomes from co-assembly of a collection of metagenomic datasets. Tests on simulated datasets revealed that MaxBin 2.0 is highly accurate in recovering individual genomes, and the application of MaxBin 2.0 to several metagenomes from environmental samples demonstrated that it could achieve two complementary goals: recovering more bacterial genomes compared to binning a single sample as well as comparing the microbial community composition between different sampling environments.Availability and implementation: MaxBin 2.0 is freely available at http://sourceforge.net/projects/maxbin/ under BSD license.Contact: ~ywwei@lbl.govSupplementary information: ~Supplementary data are available at Bioinformatics online.}
}
