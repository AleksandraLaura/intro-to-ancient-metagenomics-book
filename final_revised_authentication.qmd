## Authentication - part II - Ancient DNA authentication using metaDMG: Taxonomic profiling and DNA Damage Estimation

This section has the following outline:

13.4 Introduction
  13.4.1 Taxonomic profiling: metaDMG-cpp lca
  13.4.2 Deamination patterns: metaDMG-cpp dfit
13.5 Ancient metagenomic dataset
13.6 Ancient metagenomics with metaDMG-cpp: the workflow
13.7 Investigating the final output with R
  13.7.1 Deamination patterns
  13.7.2 Amplitude of damage vs Significance
  13.7.3 Amplitude of damage and mean fragment length through time

We will cover:

- Introduction to metaDMG parameters and recommendations
- How to analyse deamination from a metagenomic dataset with metaDMG
- How to investigate the main metaDMG statistics with R

In our exploration into ancient DNA, a central question we aim to address is: 

::: {.callout-question} 
**How ancient is an organism?**
:::

To answer this question, we focus on specific validation methods that are tailored for ancient samples. These methods allow us to assess the degree of DNA fragmentation and damage as definitive indicators of ancientness. 
Ancient DNA fragments are short (30-70 bp) and exhibit a higher proportion of C -> T misincorporations at the strand termini compared to the other single nucleotide substitutions (Figure 1).

![Figure 1. Damage plots of reads assigned to Homo sapiens with post-mortem damage pattern increasing at read termini [from metagenomic samples, adapted from @Michelsen2022]. The figure shows the damage rate f (x) = k(x)∕N(x) as a function of position x for both forward (C→T) and reverse (G→A).](assets/images/chapters/authentication/Fig_9_deamination.png)


Different tools can be utilised to assess the level of deamination at the strand termini and the most popular are [mapDamage2.0](https://academic.oup.com/bioinformatics/article/29/13/1682/184965) and [PMDtools](https://github.com/pontussk/PMDtools). However, applying these to a metagenomic dataset can be computationally demanding and time-consuming due to the tens of thousands of different taxonomic entities it can include. 

**metaDMG** is currently under development and it represents a fast, flexible, and efficient tool for performing **taxonomic profiling** (with the integrated ngsLCA algorithm) and quantifying **post-mortem DNA damage**. 
It is specially optimised for ancient metagenomic datasets where raw fastq files have been mapped against large sets of reference genomes.
metaDMG should be run on a read coordinate sorted BAM/SAM-alignment file and can calculate the degree of damage from read data mapped against single and multiple genomes by analysing mismatches and deletions contained in the MD:Z tag of the input alignment file. This reference-free approach allows for a faster processing of the deamination patterns. 

In particular, three different settings can be run: 
1. Single genome analysis with one overall global estimate of the damage patterns. Similar to [mapDamage2.0](https://academic.oup.com/bioinformatics/article/29/13/1682/184965).

```{bash, eval = F}
./metaDMG-cpp getdamage --run_mode 0
```
2. Metagenomic (e.g. multiple genome alignments) analyses. This mode provides a damage estimate per reference, taxonomic name or accession number, including all alignments without any taxonomical classification 

```{bash, eval = F}
./metaDMG-cpp getdamage --run_mode 1
```
3.	Metagenomic analyses with the integration of the taxonomy: Least Common Ancestor algorithm (ngsLCA). This allows the computation of damage estimates for alignments classified to given taxonomic levels.

```{bash, eval = F}
./metaDMG-cpp lca
```
In this section we will utilise **metaDMG-cpp lca**, since we are interested in a more comprehensive analsysis that includes the taxonomic classification of our alignments. For those interested in exploring other functionalities of metaDMG, I encourage you to visit the tool’s official [github page](https://github.com/metaDMG-dev/metaDMG-cpp) and the ngsLCA official [github page](https://github.com/miwipe/ngsLCA).


### 13.4.1 Taxonomic profiling: metaDMG-cpp lca

```{bash, eval = F}
./metaDMG-cpp lca
```
The **metaDMG-cpp lca** function is based on the ngsLCA (next-generation sequence Lowest Common Ancestor) algorithm to collect mismatch information for all reads and generate a taxonomic profile (Wang et al. 2022). It counts substitutions between read and reference on internal nodes within a taxonomy (e.g. species, genus and family level). It is built upon the [NCBI taxonomy](https://www.ncbi.nlm.nih.gov/taxonomy) and requires three files: 

nodes.dmp: taxonomic nodes and the relationships between different taxa in the tree 

access2taxID: the “taxonomy file”, sequence accession numbers, and the corresponding taxonomic IDs. 

names.dmp: scientific names of the taxa are associated with each taxon contained in nodes.dmp file.

::: {.callout-tip}
For custom reference genomes not covered by NCBI, their accession IDs and the corresponded NCBI taxonomic IDs need to be manually attached to the NCBI access2taxID file.
:::

The ngsLCA program considers a chosen similarity interval between each read and its reference in the generated bam/sam file. The similarity can be set as an edit distance [-editdist[min/max]], i.e., number of mismatches between the read to reference genome, or as a similarity distance [-simscore[low/high]], i.e., percentage of mismatches between the read to reference genome. 

The main files produced by this command have the extensions “.bdamage.gz” and “lca.gz”. The first consists of a nucleotide misincorporation matrix (also called “mismatch matrix”) which represents the nucleotide substitution counts across the reads (Table 1). The lca file reports the sequence analysed and its taxonomic path, as well as other statistics (gc content, fragment length).

We report an example of the bdamage.gz file output printed using the command **metaDMG-cpp print**:

```{bash, eval = F}
./metaDMG-cpp print file.bdamage.gz -names names.dmp > bdamage_table.tsv
```

```{r}
#| label: tbl-authentication-examplecodetable2
#| echo: false
#| results: 'asis'
#| tbl-cap: "Table 1. Example of the bdamage.gz mismatch matrix table for beech (Fagus sylvatica) of sample VM-14 provided in the exercise."
#| tbl-cap-location: top

library(tidyverse)
library(gt)

# Load the data from CSV
data <- read_csv("assets/images/chapters/authentication/bdamage_example.csv")

# Create the table with gt
data %>%
  gt() %>%
  tab_header(
    title = md("Table 1. Example of the bdamage.gz mismatch matrix table for beech (_Fagus sylvatica_) of sample VM-14 provided in the exercise.")
  ) %>%
  tab_options(
    table.width = pct(100),
    table.layout = "fixed",
    container.overflow.x = "scroll"
  )
```

### 13.4.2 Deamination patterns

**metaDMG** can perform a numerical optimisation of the deamination frequencies (C→T, G→A) using the binomial or beta-binomial likelihood models, where the latter can deal with a large amount of variance (overdispersion). This function is called the **metaDMG-cpp dfit** or damage estimates function.


```{bash, eval = F}
./metaDMG-cpp dfit 
```

**metaDMG-cpp dfit** allows us to estimate the four fit parameters of the damage model (Figure 2):
**A**: the amplitude of damage on position one;
**q**: the constant deamination background;
**c**: relative decrease of damage per position;
**ϕ**: the uncertainty of the likelihood model used (binomial or beta-binomial). 

Another important parameter is the **Zfit** or significance, which represents the number of standard deviations (“sigmas”) away from zero, or in other words, the certainty of the damage being positive.

![Figure 2. The damage model. The figure shows the misincorporations as circles and the damage as a solid line. The fit parameters are reported: A,c,q,ϕ. The uncertainty for a binomial model is in dark grey, while the uncertainty for a beta-binomial model is in light grey. (from Michelsen et al. 2022)](assets/images/chapters/authentication/F1._MichelsenB.png)

Accurate damage estimates are crucial for the authentication of the metagenomic dataset. The **number of reads** and the **significance (Zfit)** are additional parameters that can impact the accuracy and reliability of ancient DNA analysis.

Tests on a single-genome have shown how the accuracy of metaDMG dfit increases depending on the number of reads [Figure 3].

![Figure 3. The single-genome simulations on the *Homo Sapiens* genome with a mean fragment length of 60 and 10% damage. The known damage (Dknown) is shown as a dashed line. A. Estimated damage and its standard deviation (error bars) for 20 replicates (100 reads each). B. Average damage as a function of the number of reads (with the average of the standard deviations as errors). *Adapted from Michelsen et al. 2022*.](assets/images/chapters/authentication/F3_Michelsen.png)

The simulation on the *Homo Sapiens* genome, illustrated in [Figure 3, A] demonstrates the individual metaDMG damage estimates for 20 selected replications (iterations 60 to 79). When damage estimates are minimal, the distribution of Dfit is limited to positive values. This limitation can result in error bars extending into negative damage values, thus producing unrealistic estimates. As shown in [Figure 3, B], the damage tends to converge towards the known values as the number of reads increases.

In addition, the simulation reports a relationship between the amount of damage in taxa and the number of reads[Figure 4](/). 
As shown in (*Figure 4*), low expected damage (~5 %) requires about 1000 reads to be 95% certain about its estimation, while higher levels of damage (~15-30%) require fewer reads (100-500) to reach the same level of certainty. When increasing the significance threshold (Zfit) more reads are also required.

![Figure 4. Relationship between the damage and the number of reads for the simulated single-genome data. The lines represent the number of reads needed to correctly infer the amount of damage: the solid line shows a certainty of 95%, and the dashed line, a certainty of 50%. Colors represent the significance (Zfit) cuts at 2 (blue), 3 (red), and 4 (green). *Michelsen et al. 2022*.](assets/images/chapters/authentication/F4_Michelsen.png)


Simulations using metagenomic datasets have also evaluated the relationship between the amount of damage and its significance [Figure 5].

![Figure 5. The amount of damage as a function of significance (metagenomic simulations). A. damage of the ancient taxa; B. damage of the non-ancient taxa. A larger dot size indicates a higher number of reads. *Adapted from Michelsen et al. 2022.*](assets/images/chapters/authentication/F5._Michelsen.png)

As shown in [Figure 5], there is a difference in the damage estimates between the ancient and the non-ancient taxa of simulated metagenomic datasets. The non-ancient taxa (*Figure 5, A*) report significance values below 2, in contrast to the ancient taxa (*Figure 5, B*) which reach a significance of 20.
A relaxed significance threshold (Zfit > 2) and a minimum of 100 reads increase the accuracy of damage estimates to 90% of the dataset (Michelsen et al., 2022).

We also observe how the oldest samples (Cave-100 and Cave-102) which are 100 and 102 thousand years BP, show the highest amount of damage of all the metagenomes. While Pitch-6 and Cave-22 samples, which are 6 and 22 thousand years old and thus younger have almost similar levels of damage.

### 13.5 Ancient metagenomic dataset

In this section, we will use 6 metagenomic libraries downsampled with eukaryotes reads from the study by [@Zampirolo2023.12.01.569562]. The libraries originate from sediment samples of the Velký Mamut'ák rock shelter located in Northern Bohemia (Czech Republic) and covering the period between the Late Neolithic (~6100-5300 cal. BP) to more recent times (800 cal BP). 

![Figure 6. Screenshot of preprint of the source dataset by Zampirolo et al. 2023](assets/images/chapters/authentication/BioxRiv_paper.png)

### 13.6 Ancient metagenomics with metaDMG-cpp: the workflow

This section will cover the metaDMG analysis which involve taxonomic classification of the reads starting from sorted SAM files, the damage estimation and compilation of the final metaDMG output.

::: {.callout-tip}
The raw sam files we will use for the exercise are stored in `authentication/metadmg`.

We also need the taxonomy files, which are in the folder authentication/metadmg/small_taxonomy/, these include names.dmp, nodes.dmp and small_accession2taxid.txt.gz. 

Before we can initiate a new conda environment, we need to deactivate the current one:

```{bash, eval = F}
conda deactivate 
```

We work with metaDMG activating the environment with

```{bash, eval = F}
conda activate metaDMG
```
:::

::: {.callout-warning}
**metaDMG** is currently under development and it is therefore important to keep it updated. 
The best documentation is currently found in the –help function.
:::

We run the metaDMG-cpp lca to get the mismatch matrix file "bdamage.gz" that we need to estimate the dfit. 

```{bash, eval = F}
metaDMG-cpp lca --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --acc2tax authentication/metadmg/small_taxonomy/small_accession2taxid.txt.gz --sim_score_low 0.95 --sim_score_high 1.0 --how_many 30 --weight_type 1 --threads 12 --bam authentication/metadmg/VM-3_800.merged.sort.bam --out_prefix authentication/metadmg/VM-3_800.merged.bam

metaDMG-cpp lca --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --acc2tax authentication/metadmg/small_taxonomy/small_accession2taxid.txt.gz --sim_score_low 0.95 --sim_score_high 1.0 --how_many 30 --weight_type 1 --threads 12 --bam authentication/metadmg/VM-11_3000.merged.sort.bam --out_prefix authentication/metadmg/VM-11_3000.merged.bam

metaDMG-cpp lca --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --acc2tax authentication/metadmg/small_taxonomy/small_accession2taxid.txt.gz --sim_score_low 0.95 --sim_score_high 1.0 --how_many 30 --weight_type 1 --threads 12 --bam authentication/metadmg/VM-14_3900.merged.sort.bam --out_prefix authentication/metadmg/VM-14_3900.merged.bam 

metaDMG-cpp lca --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --acc2tax authentication/metadmg/small_taxonomy/small_accession2taxid.txt.gz --sim_score_low 0.95 --sim_score_high 1.0 --how_many 30 --weight_type 1 --threads 12 --bam authentication/metadmg/VM-15_4100.merged.sort.bam --out_prefix authentication/metadmg/VM-15_4100.merged.bam 

metaDMG-cpp lca --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --acc2tax authentication/metadmg/small_taxonomy/small_accession2taxid.txt.gz --sim_score_low 0.95 --sim_score_high 1.0 --how_many 30 --weight_type 1 --threads 12 --bam authentication/metadmg/VM-17_5300.merged.sort.bam --out_prefix authentication/metadmg/VM-17_5300.merged.bam 

metaDMG-cpp lca --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --acc2tax authentication/metadmg/small_taxonomy/small_accession2taxid.txt.gz --sim_score_low 0.95 --sim_score_high 1.0 --how_many 30 --weight_type 1 --threads 12 --bam authentication/metadmg/VM-19_6100.merged.sort.bam --out_prefix authentication/metadmg/VM-19_6100.merged.bam
```

We use the file generated from the previous command (bdamage.gz), containing the misincorporation matrix to calculate the deamination pattern. We use metaDMG-cpp dfit function to obtain a quick computation of a beta-binomial model. 

```{bash, eval = F}
metaDMG-cpp dfit authentication/metadmg/VM-3_800.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2  --lib ds --out authentication/metadmg/VM-3_800.merged.bam 

metaDMG-cpp dfit authentication/metadmg/VM-11_3000.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2  --lib ds --out authentication/metadmg/VM-11_3000.merged.bam 

metaDMG-cpp dfit authentication/metadmg/VM-14_3900.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2  --lib ds --out authentication/metadmg/VM-14_3900.merged.bam

metaDMG-cpp dfit authentication/metadmg/VM-15_4100.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2  --lib ds --out authentication/metadmg/VM-15_4100.merged.bam 

metaDMG-cpp dfit authentication/metadmg/VM-17_5300.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2  --lib ds --out authentication/metadmg/VM-17_5300.merged.bam 

metaDMG-cpp dfit authentication/metadmg/VM-19_6100.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2  --lib ds --out authentication/metadmg/VM-19_6100.merged.bam

```

::: {.callout-warning title="Example only -, do not run!"}
The metaDMG-cpp dfit function also allows for the computation of a binomial model, which includes additional statistics (such as bootstrap estimated parameters). For the exercise, we only run the quick statistics, but we provide an example of the codes for full stat:

```{bash, eval = F}
metaDMG-cpp dfit authentication/metadmg/VM-11_3000.merged.bam.bdamage.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes  authentication/metadmg/small_taxonomy/nodes.dmp --showfits 2 --nopt 10 --nbootstrap 20 --doboot 1 --seed 1234  --lib ds --out authentication/metadmg/VM-11_3000.merged.bam
```
:::

We run the "metaDMG-cpp aggregate" function to merge the statistics from the previous two steps and obtain a file for each sample.

```{bash, eval = F}
metaDMG-cpp aggregate authentication/metadmg/VM-3_800.merged.bam.bdamage.gz -lcastat authentication/metadmg/VM-3_800.merged.bam.stat.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --dfit authentication/metadmg/VM-3_800.merged.bam.dfit.gz --out authentication/metadmg/VM-3_aggregated_results

metaDMG-cpp aggregate authentication/metadmg/VM-11_3000.merged.bam.bdamage.gz -lcastat authentication/metadmg/VM-11_3000.merged.bam.stat.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --dfit authentication/metadmg/VM-11_3000.merged.bam.dfit.gz --out authentication/metadmg/VM-11_aggregated_results

metaDMG-cpp aggregate authentication/metadmg/VM-14_3900.merged.bam.bdamage.gz -lcastat authentication/metadmg/VM-14_3900.merged.bam.stat.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --dfit authentication/metadmg/VM-14_3900.merged.bam.dfit.gz --out authentication/metadmg/VM-14_aggregated_results

metaDMG-cpp aggregate authentication/metadmg/VM-15_4100.merged.bam.bdamage.gz -lcastat authentication/metadmg/VM-15_4100.merged.bam.stat.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --dfit authentication/metadmg/VM-15_4100.merged.bam.dfit.gz --out authentication/metadmg/VM-15_aggregated_results

metaDMG-cpp aggregate authentication/metadmg/VM-17_5300.merged.bam.bdamage.gz -lcastat authentication/metadmg/VM-17_5300.merged.bam.stat.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --dfit authentication/metadmg/VM-17_5300.merged.bam.dfit.gz --out authentication/metadmg/VM-17_aggregated_results

metaDMG-cpp aggregate authentication/metadmg/VM-19_6100.merged.bam.bdamage.gz -lcastat authentication/metadmg/VM-19_6100.merged.bam.stat.gz --names authentication/metadmg/small_taxonomy/names.dmp --nodes authentication/metadmg/small_taxonomy/nodes.dmp --dfit authentication/metadmg/VM-19_6100.merged.bam.dfit.gz --out authentication/metadmg/VM-19_aggregated_results
```

In the last step we merge the header and the filenames in a unique tab-separated file (tsv).

We first unzip the output files
```{bash, eval = F}
gunzip *_aggregated_results.stat.gz
```

Then we extract the header and we concatenate the content of all the output files in a unique tsv file.
```{bash, eval = F}
#Define header for final output table
header_file="VM-11_aggregated_results.stat"

# Get the header
header=$(head -n 1 "$header_file")

# Define the output file
output_file="concatenated_metaDMGfinal.tsv"

# Add the header to the concatenated file
echo -e "filename\t$header" > "$output_file"

for file in VM-11_aggregated_results.stat \
	    VM-14_aggregated_results.stat \
            VM-15_aggregated_results.stat \
            VM-17_aggregated_results.stat \
            VM-19_aggregated_results.stat \
            VM-3_aggregated_results.stat
do
    tail -n +2 "$file" | while read -r line; do
        echo -e "$file\t$line" >> "$output_file"
    done
done
```

## 13.7 Investigating the final output with R
We first visualise our metaDMG output manually navigating to the folder home/ubuntu/Desktop/volume/authentication/metadmg/ and clicking on "Open folder".
We can double-click on the tsv file "concatenated_metaDMGfinal.tsv" and visualise it.

We will now investigate the tsv table produced by metaDMG to authenticate damage patterns, visualise the relationship between the damage and the significance, and the degree of damage through depth and time.

::: {.callout-tip}
R packages for this exercise are located in the conda environment "authentication".

We deactivate the current conda environment and we open the environment "authentication"
```{bash}
conda deactivate metaDMG
conda activate authentication
```

We navigate to the working directory:

```{bash}
cd authentication/metadmg/figures
```

We load R by running `R` in your terminal

```{bash}
R
```

We load the libraries 

```{r}
library(tidyr)
library(dplyr)
library(forcats)
library(scales)
library(gridExtra)
library(ggplot2)
library(purrr)
library(ggpubr)
``` 
:::


#### 13.7.1 Deamination patterns

We run the damage plot to visualise the deamination patterns along forward and reverse strands, and we save the results per each taxon detected in the samples.

We will use the function "get_dmg_decay_fit" to visualise damage pattern. The function is saved in authentication/metadmg/script/, so we only need to run the following command to recall it:

```{r}
source("authentication/metadmg/scripts/get_dmg_decay_fit.R")
```


But if you are curious and want to know how it works, here is the function itself:
```{r eval=F}
get_dmg_decay_fit <- function(df, orient = "fwd", pos = 30, p_breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7), y_max = 0.7, y_min = -0.01) {
  df_dx_fwd <- df %>%
    select(taxid, name, label, starts_with("fwdx")) %>%
    select(-starts_with("fwdxConf")) %>% 
    pivot_longer(names_to = "type", values_to = "Dx_fwd", c(-taxid, -name, -label)) %>%
    mutate(x = gsub("fwdx", "", type)) %>%
    select(-type)
  
  df_dx_rev <- df %>%
    select(taxid, name, label, starts_with("bwdx")) %>%
    select(-starts_with("bwdxConf")) %>%
    pivot_longer(names_to = "type", values_to = "Dx_rev", c(-taxid, -name, -label)) %>%
    mutate(x = gsub("bwdx", "", type)) %>%
    select(-type)
  
  df_dx_std_fwd <- df %>%
    select(taxid, name, label, starts_with("fwdxConf")) %>%
    pivot_longer(names_to = "type", values_to = "Dx_std_fwd", c(-taxid, -name, -label)) %>%
    mutate(x = gsub("fwdxConf", "", type)) %>%
    select(-type)
  
  df_dx_std_rev <- df %>%
    select(taxid, name, label, starts_with("bwdxConf")) %>%
    pivot_longer(names_to = "type", values_to = "Dx_std_rev", c(-taxid, -name, -label)) %>%
    mutate(x = gsub("bwdxConf", "", type)) %>%
    select(-type)
  
  df_fit_fwd <- df %>%
    select(taxid, name, label, starts_with("fwf")) %>%
    pivot_longer(names_to = "type", values_to = "f_fwd", c(-taxid, -name, -label)) %>%
    mutate(x = gsub("fwf", "", type)) %>%
    select(-type)
  
  df_fit_rev <- df %>%
    select(taxid, name, label, starts_with("bwf")) %>%
    pivot_longer(names_to = "type", values_to = "f_rev", c(-taxid, -name, -label)) %>%
    mutate(x = gsub("bwf", "", type)) %>%
    select(-type)
  
  dat <- df_dx_fwd %>%
    inner_join(df_dx_rev, by = c("taxid", "name", "label", "x")) %>%
    inner_join(df_dx_std_fwd, by = c("taxid", "name", "label", "x")) %>%
    inner_join(df_dx_std_rev, by = c("taxid", "name", "label", "x")) %>%
    inner_join(df_fit_fwd, by = c("taxid", "name", "label", "x")) %>%
    inner_join(df_fit_rev, by = c("taxid", "name", "label", "x")) %>%
    mutate(x = as.numeric(x)) %>%
    filter(x <= pos) %>%
    rowwise() %>%
    mutate(Dx_fwd_min = Dx_fwd - Dx_std_fwd,
           Dx_fwd_max = Dx_fwd + Dx_std_fwd,
           Dx_rev_min = Dx_rev - Dx_std_rev,
           Dx_rev_max = Dx_rev + Dx_std_rev)
  
  fwd_max <- dat %>%
    group_by(as.character(x)) %>%
    summarise(val = mean(Dx_std_fwd) + sd(Dx_std_fwd)) %>%
    pull(val) %>%
    max()
  
  fwd_min <- dat %>%
    group_by(as.character(x)) %>%
    summarise(val = mean(Dx_std_fwd) - sd(Dx_std_fwd)) %>%
    pull(val) %>%
    min()
  
  rev_max <- dat %>%
    group_by(as.character(x)) %>%
    summarise(val = mean(Dx_std_rev) + sd(Dx_std_rev)) %>%
    pull(val) %>%
    max()
  
  rev_min <- dat %>%
    group_by(as.character(x)) %>%
    summarise(val = mean(Dx_std_rev) - sd(Dx_std_rev)) %>%
    pull(val) %>%
    min()
  
  if (orient == "fwd") {
    ggplot() +
      geom_ribbon(data = dat, aes(x, ymin = Dx_fwd_min, ymax = Dx_fwd_max, group = interaction(name, taxid)), alpha = 0.6, fill = "darkcyan") +
      geom_line(data = dat, aes(x, Dx_fwd, group = interaction(name, taxid)), color = "black") +
      geom_point(data = dat, aes(x, f_fwd), alpha = .50, size = 2, fill = "black") +
      theme_test() +
      xlab("Position") +
      ylab("Frequency") +
      scale_y_continuous(limits = c(y_min, y_max), breaks = p_breaks) +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
      facet_wrap(~label, ncol = 1)
  } else {
    ggplot() +
      geom_ribbon(data = dat, aes(x, ymin = Dx_rev_min, ymax = Dx_rev_max, group = interaction(name, taxid)), alpha = 0.6, fill = "orange") +
      geom_path(data = dat, aes(x, Dx_rev, group = interaction(name, taxid)), color = "black") +
      geom_point(data = dat, aes(x, f_rev), alpha = .50, size = 2, fill = "black") +
      theme_test() +
      xlab("Position") +
      ylab("Frequency") +
      scale_x_continuous(trans = "reverse") +
      scale_y_continuous(limits = c(y_min, y_max), position = "right", breaks = p_breaks) +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
      facet_wrap(~label, ncol = 1)
  }
}
```

We load our metaDMG output data (tsv file) and generate the damage plots using the function "get-damage".

```{r}
df <- read.csv("authentication/metadmg/concatenated_metaDMGfinal.tsv",  sep = "\t")

#Rename sample column
colnames(df)[colnames(df) == 'filename'] <- 'sample'

#Modify sample name with short names
df$sample[df$sample == "VM-11_aggregated_results.stat"] <- "VM-11"
df$sample[df$sample == "VM-14_aggregated_results.stat"] <- "VM-14"
df$sample[df$sample == "VM-15_aggregated_results.stat"] <- "VM-15"
df$sample[df$sample == "VM-17_aggregated_results.stat"] <- "VM-17"
df$sample[df$sample == "VM-19_aggregated_results.stat"] <- "VM-19"
df$sample[df$sample == "VM-3_aggregated_results.stat"] <- "VM-3"

#Setting filtering theshold for ancient reads
minDMG = 0.02 # filter criteria, plot only taxa above set value
zfit = 2 # minimum significance, the higher the better, 2 would mean that we estimante the damage with 95% confidence. 
MinLength = 35 # minimum mean readlength, while we set a hard filter initially while trimming, we would like the mean readlength to be 35 or higher. 
reads = 200 # number of reads required depends on the amount of damage and the significance

#Subsetting only animals and plants, at the genus level, number of reads > 200.
dt1 <- df %>% filter(A > minDMG, nreads >= reads, mean_rlen >= MinLength, Zfit  > zfit, grepl("\\bgenus\\b", rank), !grepl("Bacteria",taxa_path))

#deamination plot with facet wrap per each taxon in a sample
tax_g_list <- unique(dt1$name)
nrank <- "rank" # Replace with the actual rank column name

X <- tax_g_list 
purrr::map(tax_g_list, function(X, nrank) {
  sel_tax <- dt1 %>%
    rename(label = sample) %>%
    #filter(Genome_Id %in% (tax_superg %>% filter(Taxa_Super_Groups == X) %>% pull(Genome_Id))) %>%
    filter(name == X) %>%
    filter(rank == rank) %>%
    select(name, label) %>%
    distinct() %>%
    arrange(name)
  if (nrow(sel_tax) > 0) {
    n_readsa <- dt1 %>%
      inner_join(sel_tax) %>%
      filter(rank == rank) %>%
      pull(nreads) %>%
      sum()
    ggpubr::ggarrange(plotlist = list(
      get_dmg_decay_fit(df = dt1 %>% rename(label = sample) %>% inner_join(sel_tax) %>% filter(rank == rank), orient = "fwd", y_max = 0.70) +
        ggtitle(paste0(X, " nreads=", n_readsa, " Forward")),
      get_dmg_decay_fit(df = dt1 %>% rename(label = sample)  %>% inner_join(sel_tax) %>% filter(rank == rank), orient = "rev", y_max = 0.70) +
        ggtitle(paste0(X, " nreads=", n_readsa, " Reverse"))
    ), align = "hv")
    ggsave(paste0(X, "-dmg.pdf"), plot = last_plot(), width = 8, height = 4)
  }
})
``` 
![Figure 7. Deamination patterns for sheep (*Ovis*) and beech (*Fagus*) reads.](assets/images/chapters/authentication/Fagus_Ovis-dmg.png)

### 13.7.2 Amplitude of damage vs Significance
We provide an R script to investigate the main statistics. 
Here we visualise the amplitude of damage (A) and its significance (Zfit), for the full dataset but filtering it to a minimum of 100 reads and at the genus level. 

```{r eval=F}
#Subset dataset at genus level
dt2 <- df %>% filter(grepl("\\bgenus\\b", rank))

#plotting  amplitude of damage vs its significance 
p1 <- ggplot(dt2, aes(y=A, x=Zfit)) + 
  geom_point(aes(size=nreads), col ="dark green") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust =1)) +
  scale_size_continuous(labels = function(x) format(x, scientific = FALSE)) +
  xlab("significance") + ylab("damage") + theme_minimal()
p1

#Plotting only animals and plants at genus level
#subset dataset
dt3 <- dt2 %>% filter(nreads > 100, grepl("\\bgenus\\b", rank), grepl("Metazoa", taxa_path) | grepl("Viridiplant", taxa_path))

#Adding factor column for Kingdom
dt3 <- dt3 %>% 
  mutate(Kingdom =   # creating our new column
           case_when(grepl("Viridiplant", taxa_path) ~ "Viridiplantae",
                     grepl("Metazoa",taxa_path) ~ "Metazoa"))

#Plotting  amplitude of damage vs its significance 
p2 <- ggplot(dt3, aes(y=A, x=Zfit)) + 
  geom_point(aes(size=nreads, col=Kingdom)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust =1)) +
  scale_color_manual(values = c("#8B1A1A", "#458B00"))+
  scale_size_continuous(labels = function(x) format(x, scientific = FALSE)) +
  xlab("significance") + ylab("damage") + theme_minimal()
p2

#Save the plots as a PDF file
ggsave("p1.pdf", plot = p1, width = 8, height = 6)
ggsave("p2.pdf", plot = p2, width = 8, height = 6)
``` 

![Figure 8. Amplitude of damage (A) vs significance (Zfit) for animals and plants.](assets/images/chapters/authentication/p2.png)
### 13.7.3 Amplitude of damage and mean fragment length through time
Here we visualise the amplitude of damage (A) and the mean length of the fragments (mean_rlen) by depth and by date (BP) for the full dataset but filtering it to a minimum of 100 reads and at the genus level.

```{r eval=F}
#Import the metadata 
depth_data <- read.csv ("authentication/metadmg/figures/depth_data.csv", sep = ",")
View (depth_data)

#Merge context_data and depth_data with dataframe (adding new column for dates BP)
df$new <- depth_data$Date_BP[match(df$sample, depth_data$Sample_ID)]
names(df)[names(df) == 'new'] <- 'Date_BP'

# Convert Date_BP columns to factors (categorical variable) 
df$Date_BP <- as.factor(df$Date_BP)

#Plotting damage (A) by period (dates BP)
p3a<- dt4 %>%
  mutate(Date_BP = fct_relevel(Date_BP,
                             "6100","5300","4100","3900","3000", "800")) %>%
  ggplot(aes(x=A, y=Date_BP))+ 
  geom_boxplot(aes(x=A, y=Date_BP, fill = sample))+
  geom_point(aes(fill = sample), size = 3, shape = 21, color = "black", stroke = .5) +
  scale_x_continuous(limits = c(0, 0.20), breaks = seq(0, 0.20, by = 0.05)) +
  theme_minimal() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p3a

#Plotting mean length (mean_rlen) by period (dates BP)
p3b<- dt4 %>%
  mutate(Date_BP = fct_relevel(Date_BP,
                             "6100","5300","4100","3900","3000", "800")) %>%
  ggplot(aes(x=mean_rlen, y=Date_BP))+ 
  geom_boxplot(aes(x=mean_rlen, y=Date_BP, fill = sample)) +
  geom_point(aes(fill = sample), size = 3, shape = 21, color = "black", stroke = .5) +
  scale_x_continuous(limits = c(30, 80), breaks = seq(30, 80, by = 10)) +
  theme_minimal() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p3b

#Combining the plots
p3 <- grid.arrange(p3a, p3b,
                   ncol = 2, nrow = 1)
p3

#Save plot
ggsave("p3.pdf", plot = p4, width = 10, height = 8)
``` 

![Figure 9. Amplitude of damage (A) and mean fragment length (mean_rlen) through time.](assets/images/chapters/authentication/p3.png)

::: {.callout-tip}
Once finished examining the plots you can quit R
```{bash, eval = F}
## Press 'n' when asked if you want to save your workspace image.
quit()
```
:::

::: {.callout-tip}
You can manually navigate to the folder home/ubuntu/Desktop/volume/authentication/metadmg/figures/
And click “Open folder”
You can double-click on the pdf files to visualise them.
:::

## Aknowledgments
We thank Mikkel Winther Pedersen and Antonio Fernandez Guerra for their contribution to the development of this section (*Authentication - part II - Ancient DNA authentication using metaDMG*).

## Recommended Reading

1. Clio Der Sarkissian, Irina M. Velsko, Anna K. Fotakis, Åshild J. Vågene, Alexander Hübner, and James A. Fellows Yates, Ancient Metagenomic Studies: Considerations for the Wider Scientific Community, mSystems 2021 Volume 6  Issue 6  e01315-21.

2. Warinner C, Herbig A, Mann A, Fellows Yates JA, Weiß CL, Burbano HA, Orlando L, Krause J. A Robust Framework for Microbial Archaeology. Annu Rev Genomics Hum Genet. 2017 Aug 31;18:321-356. doi: 10.1146/annurev-genom-091416-035526. Epub 2017 Apr 26. PMID: 28460196; PMCID: PMC5581243.

3. Orlando, L., Allaby, R., Skoglund, P. et al. Ancient DNA analysis. Nat Rev Methods Primers 1, 14 (2021). https://doi.org/10.1038/s43586-020-00011-0

## Resources

1. **KrakenUniq**: Breitwieser, F. P., Baker, D. N., & Salzberg, S. L. (2018). KrakenUniq: confident and fast metagenomics classification using unique k-mer counts. Genome Biology, vol. 19(1), p. 1–10. http://www.ec.gc.ca/education/default.asp?lang=En&n=44E5E9BB-1

2. **Samtools**: Heng Li, Bob Handsaker, Alec Wysoker, Tim Fennell, Jue Ruan, Nils Homer, Gabor Marth, Goncalo Abecasis, Richard Durbin, 1000 Genome Project Data Processing Subgroup, The Sequence Alignment/Map format and SAMtools, Bioinformatics, Volume 25, Issue 16, 15 August 2009, Pages 2078–2079, https://doi.org/10.1093/bioinformatics/btp352

3. **PMDtools**: Skoglund P, Northoff BH, Shunkov MV, Derevianko AP, Pääbo S, Krause J, Jakobsson M. Separating endogenous ancient DNA from modern day contamination in a Siberian Neandertal. Proc Natl Acad Sci U S A. 2014 Feb 11;111(6):2229-34. doi: 10.1073/pnas.1318934111. Epub 2014 Jan 27. PMID: 24469802; PMCID: PMC3926038.

4. **pyDamage**: Borry M, Hübner A, Rohrlach AB, Warinner C. PyDamage: automated ancient damage identification and estimation for contigs in ancient DNA de novo assembly. PeerJ. 2021 Jul 27;9:e11845. doi: 10.7717/peerj.11845. PMID: 34395085; PMCID: PMC8323603.

11. **metaDMG-cpp**: https://github.com/metaDMG-dev/metaDMG-cpp

2. **ngsLCA**: Wang, Y., Korneliussen, T. S., Holman, L. E., Manica, A., & Pedersen, M. W. (2022). ngs LCA—A toolkit for fast and flexible lowest common ancestor inference and taxonomic profiling of metagenomic data. Methods in Ecology and Evolution, 13(12), 2699-2708. (https://github.com/miwipe/ngsLCA)

## References
